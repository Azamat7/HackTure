[{"index": 0, "start": 0, "dur": 0.04, "end": 0.04}, {"index": 1, "start": 0.04, "dur": 2.37, "end": 2.41, "text": "The following content is\nprovided under a Creative"}, {"index": 2, "start": 2.41, "dur": 1.38, "end": 3.79, "text": "Commons license."}, {"index": 3, "start": 3.79, "dur": 2.24, "end": 6.03, "text": "Your support will help\nMIT OpenCourseWare"}, {"index": 4, "start": 6.03, "dur": 4.07, "end": 10.1, "text": "continue to offer high-quality\neducational resources for free."}, {"index": 5, "start": 10.1, "dur": 2.58, "end": 12.68, "text": "To make a donation or to\nview additional materials"}, {"index": 6, "start": 12.68, "dur": 3.816, "end": 16.496, "text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare"}, {"index": 7, "start": 16.496, "dur": 0.624, "end": 17.12, "text": "at ocw.mit.edu."}, {"index": 8, "start": 17.12, "dur": 13.765, "end": 30.885}, {"index": 9, "start": 30.885, "dur": 2.97, "end": 33.855, "text": "[MUSIC PLAYING]"}, {"index": 10, "start": 33.855, "dur": 3.925, "end": 37.78}, {"index": 11, "start": 37.78, "dur": 2.25, "end": 40.03, "text": "PATRICK H. WINSTON: Well,\nwhat we&#39;re going to do today"}, {"index": 12, "start": 40.03, "dur": 2.08, "end": 42.11, "text": "is climb a pretty big\nmountain because we&#39;re"}, {"index": 13, "start": 42.11, "dur": 1.81, "end": 43.92, "text": "going to go from a\nneural net with two"}, {"index": 14, "start": 43.92, "dur": 4.02, "end": 47.94, "text": "parameters to discussing\nthe kind of neural nets"}, {"index": 15, "start": 47.94, "dur": 8.65, "end": 56.59, "text": "in which people end up dealing\nwith 60 million parameters."}, {"index": 16, "start": 56.59, "dur": 2.586, "end": 59.176, "text": "So it&#39;s going to be\na pretty big jump."}, {"index": 17, "start": 59.176, "dur": 1.374, "end": 60.55, "text": "Along the way are\na couple things"}, {"index": 18, "start": 60.55, "dur": 5.2, "end": 65.75, "text": "I wanted to underscore from\nour previous discussion."}, {"index": 19, "start": 65.75, "dur": 2.59, "end": 68.34, "text": "Last time, I tried to\ndevelop some intuition"}, {"index": 20, "start": 68.34, "dur": 3.26, "end": 71.6, "text": "for the kinds of formulas\nthat you use to actually do"}, {"index": 21, "start": 71.6, "dur": 2.63, "end": 74.23, "text": "the calculations in a\nsmall neural net about how"}, {"index": 22, "start": 74.23, "dur": 1.93, "end": 76.16, "text": "the weights are going to change."}, {"index": 23, "start": 76.16, "dur": 2.07, "end": 78.23, "text": "And the main thing\nI tried to emphasize"}, {"index": 24, "start": 78.23, "dur": 12.19, "end": 90.42, "text": "is that when you have a\nneural net like this one,"}, {"index": 25, "start": 90.42, "dur": 6.19, "end": 96.61, "text": "everything is sort of\ndivided in each column."}, {"index": 26, "start": 96.61, "dur": 5.75, "end": 102.36, "text": "You can&#39;t have the performance\nbased on this output"}, {"index": 27, "start": 102.36, "dur": 2.58, "end": 104.94, "text": "affect some weight\nchange back here"}, {"index": 28, "start": 104.94, "dur": 4.21, "end": 109.15, "text": "without going through this\nfinite number of output"}, {"index": 29, "start": 109.15, "dur": 1.886, "end": 111.036, "text": "variables, the y1s."}, {"index": 30, "start": 111.036, "dur": 6.274, "end": 117.31, "text": "And by the way, there&#39;s no y2\nand y4-- there&#39;s no y2 and y3."}, {"index": 31, "start": 117.31, "dur": 3.2, "end": 120.51, "text": "Dealing with this is really\na notational nightmare,"}, {"index": 32, "start": 120.51, "dur": 3.38, "end": 123.89, "text": "and I spent a lot\nof time yesterday"}, {"index": 33, "start": 123.89, "dur": 2.259, "end": 126.149, "text": "trying to clean it\nup a little bit."}, {"index": 34, "start": 126.149, "dur": 1.541, "end": 127.69, "text": "But basically, what\nI&#39;m trying to say"}, {"index": 35, "start": 127.69, "dur": 2.269, "end": 129.959, "text": "has nothing to do with\nthe notation I have used"}, {"index": 36, "start": 129.959, "dur": 1.541, "end": 131.5, "text": "but rather with the\nfact that there&#39;s"}, {"index": 37, "start": 131.5, "dur": 3.624, "end": 135.124, "text": "a limited number of ways in\nwhich that can influence this,"}, {"index": 38, "start": 135.124, "dur": 2.166, "end": 137.29, "text": "even though the number of\npaths through this network"}, {"index": 39, "start": 137.29, "dur": 2.64, "end": 139.93, "text": "can be growing exponential."}, {"index": 40, "start": 139.93, "dur": 2.91, "end": 142.84, "text": "So those equations\nunderneath are"}, {"index": 41, "start": 142.84, "dur": 3.58, "end": 146.42, "text": "equations that derive\nfrom trying to figure out"}, {"index": 42, "start": 146.42, "dur": 5.27, "end": 151.69, "text": "how the output performance\ndepends on some"}, {"index": 43, "start": 151.69, "dur": 1.93, "end": 153.62, "text": "of these weights back here."}, {"index": 44, "start": 153.62, "dur": 2.56, "end": 156.18, "text": "And what I&#39;ve calculated\nis I&#39;ve calculated"}, {"index": 45, "start": 156.18, "dur": 4.82, "end": 161, "text": "the dependence of\nthe performance on w1"}, {"index": 46, "start": 161, "dur": 3.26, "end": 164.26, "text": "going that way, and\nI&#39;ve also calculated"}, {"index": 47, "start": 164.26, "dur": 8.16, "end": 172.42, "text": "the dependence of performance\non w1 going that way."}, {"index": 48, "start": 172.42, "dur": 3.49, "end": 175.91, "text": "So that&#39;s one of the\nequations I&#39;ve got down there."}, {"index": 49, "start": 175.91, "dur": 2.92, "end": 178.83, "text": "And another one\ndeals with w3, and it"}, {"index": 50, "start": 178.83, "dur": 8.23, "end": 187.06, "text": "involves going both\nthis way and this way."}, {"index": 51, "start": 187.06, "dur": 3.05, "end": 190.11, "text": "And all I&#39;ve done in both\ncases, in all four cases,"}, {"index": 52, "start": 190.11, "dur": 3.24, "end": 193.35, "text": "is just take the partial\nderivative of performance"}, {"index": 53, "start": 193.35, "dur": 2.4, "end": 195.75, "text": "with respect to those weights\nand use the chain rule"}, {"index": 54, "start": 195.75, "dur": 1.52, "end": 197.27, "text": "to expand it."}, {"index": 55, "start": 197.27, "dur": 8.462, "end": 205.732, "text": "And when I do that,\nthis is the stuff I get."}, {"index": 56, "start": 205.732, "dur": 2.208, "end": 207.94, "text": "And that&#39;s just a whole\nbunch of partial derivatives."}, {"index": 57, "start": 207.94, "dur": 2.57, "end": 210.51, "text": "But if you look at it and let\nit sing a little bit to you,"}, {"index": 58, "start": 210.51, "dur": 1.999, "end": 212.509, "text": "what you see is that\nthere&#39;s a lot of redundancy"}, {"index": 59, "start": 212.509, "dur": 1.761, "end": 214.27, "text": "in the computation."}, {"index": 60, "start": 214.27, "dur": 4.72, "end": 218.99, "text": "So for example, this\nguy here, partial"}, {"index": 61, "start": 218.99, "dur": 2.81, "end": 221.8, "text": "of performance\nwith respect to w1,"}, {"index": 62, "start": 221.8, "dur": 3.55, "end": 225.35, "text": "depends on both\npaths, of course."}, {"index": 63, "start": 225.35, "dur": 5.8, "end": 231.15, "text": "But look at the first elements\nhere, these guys right here."}, {"index": 64, "start": 231.15, "dur": 2.7, "end": 233.85, "text": "And look at the first\nelements in the expression"}, {"index": 65, "start": 233.85, "dur": 2.36, "end": 236.21, "text": "for calculating the partial\nderivative of performance"}, {"index": 66, "start": 236.21, "dur": 3.794, "end": 240.004, "text": "with respect to w3, these guys."}, {"index": 67, "start": 240.004, "dur": 4.608, "end": 244.612}, {"index": 68, "start": 244.612, "dur": 0.708, "end": 245.32, "text": "They&#39;re the same."}, {"index": 69, "start": 245.32, "dur": 2.6, "end": 247.92}, {"index": 70, "start": 247.92, "dur": 4.39, "end": 252.31, "text": "And not only that, if you\nlook inside these expressions"}, {"index": 71, "start": 252.31, "dur": 4.089, "end": 256.399, "text": "and look at this\nparticular piece here,"}, {"index": 72, "start": 256.399, "dur": 2.411, "end": 258.81, "text": "you see that that is\nan expression that"}, {"index": 73, "start": 258.81, "dur": 2.969, "end": 261.779, "text": "was needed in order\nto calculate one"}, {"index": 74, "start": 261.779, "dur": 2.931, "end": 264.71, "text": "of the downstream weights,\nthe changes in one"}, {"index": 75, "start": 264.71, "dur": 2.66, "end": 267.37, "text": "of the downstream weights."}, {"index": 76, "start": 267.37, "dur": 2.7, "end": 270.07, "text": "But it happens to be the same\nthing as you see over here."}, {"index": 77, "start": 270.07, "dur": 2.71, "end": 272.78}, {"index": 78, "start": 272.78, "dur": 8.752, "end": 281.532, "text": "And likewise, this piece is the\nsame thing you see over here."}, {"index": 79, "start": 281.532, "dur": 3.098, "end": 284.63}, {"index": 80, "start": 284.63, "dur": 2.55, "end": 287.18, "text": "So each time you move\nfurther and further back"}, {"index": 81, "start": 287.18, "dur": 2.11, "end": 289.29, "text": "from the outputs\ntoward the inputs,"}, {"index": 82, "start": 289.29, "dur": 1.98, "end": 291.27, "text": "you&#39;re reusing a\nlot of computation"}, {"index": 83, "start": 291.27, "dur": 2.91, "end": 294.18, "text": "that you&#39;ve already done."}, {"index": 84, "start": 294.18, "dur": 3.07, "end": 297.25, "text": "So I&#39;m trying to find a\nway to sloganize this,"}, {"index": 85, "start": 297.25, "dur": 5.03, "end": 302.28, "text": "and what I&#39;ve come up with is\nwhat&#39;s done is done and cannot"}, {"index": 86, "start": 302.28, "dur": 0.98, "end": 303.26, "text": "be-- no, no."}, {"index": 87, "start": 303.26, "dur": 1.82, "end": 305.08, "text": "That&#39;s not quite right, is it?"}, {"index": 88, "start": 305.08, "dur": 5.01, "end": 310.09, "text": "It&#39;s what&#39;s computed is computed\nand need not be recomputed."}, {"index": 89, "start": 310.09, "dur": 0.629, "end": 310.719, "text": "OK?"}, {"index": 90, "start": 310.719, "dur": 1.291, "end": 312.01, "text": "So that&#39;s what&#39;s going on here."}, {"index": 91, "start": 312.01, "dur": 4.17, "end": 316.18, "text": "And that&#39;s why this is\na calculation that&#39;s"}, {"index": 92, "start": 316.18, "dur": 5.895, "end": 322.075, "text": "linear in the depths of the\nneural net, not exponential."}, {"index": 93, "start": 322.075, "dur": 2.375, "end": 324.45, "text": "There&#39;s another thing I wanted\nto point out in connection"}, {"index": 94, "start": 324.45, "dur": 4.45, "end": 328.9, "text": "with these neural nets."}, {"index": 95, "start": 328.9, "dur": 1.5, "end": 330.4, "text": "And that has to do\nwith what happens"}, {"index": 96, "start": 330.4, "dur": 4.47, "end": 334.87, "text": "when we look at a single neuron\nand note that what we&#39;ve got"}, {"index": 97, "start": 334.87, "dur": 3.05, "end": 337.92, "text": "is we&#39;ve got a bunch of\nweights that you multiply times"}, {"index": 98, "start": 337.92, "dur": 1.495, "end": 339.415, "text": "a bunch of inputs like so."}, {"index": 99, "start": 339.415, "dur": 7.545, "end": 346.96}, {"index": 100, "start": 346.96, "dur": 4.43, "end": 351.39, "text": "And then those are all\nsummed up in a summing box"}, {"index": 101, "start": 351.39, "dur": 6.53, "end": 357.92, "text": "before they enter some kind\nof non-linearity, in our case"}, {"index": 102, "start": 357.92, "dur": 2.56, "end": 360.48, "text": "a sigmoid function."}, {"index": 103, "start": 360.48, "dur": 5.41, "end": 365.89, "text": "But if I ask you to write down\nthe expression for the value"}, {"index": 104, "start": 365.89, "dur": 1.26, "end": 367.15, "text": "we&#39;ve got there, what is it?"}, {"index": 105, "start": 367.15, "dur": 5.922, "end": 373.072, "text": "Well, it&#39;s just the sum\nof the w&#39;s times the x&#39;s."}, {"index": 106, "start": 373.072, "dur": 3.498, "end": 376.57}, {"index": 107, "start": 376.57, "dur": 0.51, "end": 377.08, "text": "What&#39;s that?"}, {"index": 108, "start": 377.08, "dur": 3.51, "end": 380.59}, {"index": 109, "start": 380.59, "dur": 2.257, "end": 382.847, "text": "That&#39;s the dot product."}, {"index": 110, "start": 382.847, "dur": 2.083, "end": 384.93, "text": "Remember a few lectures\nago I said that some of us"}, {"index": 111, "start": 384.93, "dur": 3.76, "end": 388.69, "text": "believe that the dot product is\na fundamental calculation that"}, {"index": 112, "start": 388.69, "dur": 2.07, "end": 390.76, "text": "takes place in our heads?"}, {"index": 113, "start": 390.76, "dur": 3.03, "end": 393.79, "text": "So this is why we think so."}, {"index": 114, "start": 393.79, "dur": 3.09, "end": 396.88, "text": "If neural nets are doing\nanything like this,"}, {"index": 115, "start": 396.88, "dur": 2.32, "end": 399.2, "text": "then there&#39;s a dot product\nbetween some weights"}, {"index": 116, "start": 399.2, "dur": 2.05, "end": 401.25, "text": "and some input values."}, {"index": 117, "start": 401.25, "dur": 2.65, "end": 403.9, "text": "Now, it&#39;s a funny\nkind of dot product"}, {"index": 118, "start": 403.9, "dur": 3.51, "end": 407.41, "text": "because in the models\nthat we&#39;ve been using,"}, {"index": 119, "start": 407.41, "dur": 3.48, "end": 410.89, "text": "these input variables are\nall or none, or 0 or 1."}, {"index": 120, "start": 410.89, "dur": 1.61, "end": 412.5, "text": "But that&#39;s OK."}, {"index": 121, "start": 412.5, "dur": 1.61, "end": 414.11, "text": "I have it on good\nauthority that there"}, {"index": 122, "start": 414.11, "dur": 3.98, "end": 418.09, "text": "are neurons in our head\nfor which the values that"}, {"index": 123, "start": 418.09, "dur": 3.51, "end": 421.6, "text": "are produced are not\nexactly all or none"}, {"index": 124, "start": 421.6, "dur": 2.35, "end": 423.95, "text": "but rather have a kind of\nproportionality to them."}, {"index": 125, "start": 423.95, "dur": 3.9, "end": 427.85, "text": "So you get a real dot product\ntype of operation out of that."}, {"index": 126, "start": 427.85, "dur": 1.66, "end": 429.51, "text": "So that&#39;s by way of\na couple of asides"}, {"index": 127, "start": 429.51, "dur": 1.89, "end": 431.4, "text": "that I wanted to\nunderscore before we"}, {"index": 128, "start": 431.4, "dur": 4.96, "end": 436.36, "text": "get into the center\nof today&#39;s discussion,"}, {"index": 129, "start": 436.36, "dur": 4.47, "end": 440.83, "text": "which will be to talk about\nthe so-called deep nets."}, {"index": 130, "start": 440.83, "dur": 3.06, "end": 443.89, "text": "Now, let&#39;s see,\nwhat&#39;s a deep net do?"}, {"index": 131, "start": 443.89, "dur": 5.93, "end": 449.82, "text": "Well, from last time, you\nknow that a deep net does"}, {"index": 132, "start": 449.82, "dur": 4.22, "end": 454.04, "text": "that sort of thing, and\nit&#39;s interesting to look"}, {"index": 133, "start": 454.04, "dur": 2.43, "end": 456.47, "text": "at some of the offerings here."}, {"index": 134, "start": 456.47, "dur": 3.9, "end": 460.37, "text": "By the way, how good was\nthis performance in 2012?"}, {"index": 135, "start": 460.37, "dur": 4.26, "end": 464.63, "text": "Well, it turned out\nthat the fraction"}, {"index": 136, "start": 464.63, "dur": 4.25, "end": 468.88, "text": "of the time that the\nsystem had the right answer"}, {"index": 137, "start": 468.88, "dur": 3.81, "end": 472.69, "text": "in its top five\nchoices was about 15%."}, {"index": 138, "start": 472.69, "dur": 2.7, "end": 475.39, "text": "And the fraction of the time\nthat it got exactly the right"}, {"index": 139, "start": 475.39, "dur": 4.51, "end": 479.9, "text": "answer as its top pick\nwas about 37%-- error,"}, {"index": 140, "start": 479.9, "dur": 5.84, "end": 485.74, "text": "15% error if you count it as\nan error if it&#39;s-- what am I"}, {"index": 141, "start": 485.74, "dur": 1.22, "end": 486.96, "text": "saying?"}, {"index": 142, "start": 486.96, "dur": 2.48, "end": 489.44, "text": "You got it right if you\ngot it in the top five."}, {"index": 143, "start": 489.44, "dur": 3.22, "end": 492.66, "text": "An error rate on that\ncalculation, about 15%."}, {"index": 144, "start": 492.66, "dur": 3.45, "end": 496.11, "text": "If you say you only get it right\nif it was your top choice, then"}, {"index": 145, "start": 496.11, "dur": 2.72, "end": 498.83, "text": "the error rate was about 37%."}, {"index": 146, "start": 498.83, "dur": 2.7, "end": 501.53, "text": "So pretty good, especially\nsince some of these things"}, {"index": 147, "start": 501.53, "dur": 3.072, "end": 504.602, "text": "are highly ambiguous even to us."}, {"index": 148, "start": 504.602, "dur": 1.458, "end": 506.06, "text": "And what kind of\na system did that?"}, {"index": 149, "start": 506.06, "dur": 4.55, "end": 510.61, "text": "Well, it wasn&#39;t one\nthat looked exactly"}, {"index": 150, "start": 510.61, "dur": 3.21, "end": 513.82, "text": "like that, although that\nis the essence of it."}, {"index": 151, "start": 513.82, "dur": 2.627, "end": 516.447, "text": "The system actually\nlooked like that."}, {"index": 152, "start": 516.447, "dur": 1.583, "end": 518.03, "text": "There&#39;s quite a lot\nof stuff in there."}, {"index": 153, "start": 518.03, "dur": 2.5, "end": 520.53, "text": "And what I&#39;m going to talk about\nis not exactly this system,"}, {"index": 154, "start": 520.53, "dur": 4, "end": 524.53, "text": "but I&#39;m going to talk about the\nstuff of which such systems are"}, {"index": 155, "start": 524.53, "dur": 2.35, "end": 526.88, "text": "made because there&#39;s\nnothing particularly"}, {"index": 156, "start": 526.88, "dur": 1.04, "end": 527.92, "text": "special about this."}, {"index": 157, "start": 527.92, "dur": 3.07, "end": 530.99, "text": "It just happens to be\na particular assembly"}, {"index": 158, "start": 530.99, "dur": 3.25, "end": 534.24, "text": "of components that tend to\nreappear when anyone does"}, {"index": 159, "start": 534.24, "dur": 2.67, "end": 536.91, "text": "this sort of neural net stuff."}, {"index": 160, "start": 536.91, "dur": 2.12, "end": 539.03, "text": "So let me explain that this way."}, {"index": 161, "start": 539.03, "dur": 6.08, "end": 545.11, "text": "First thing I need to talk\nabout is the concept of-- well,"}, {"index": 162, "start": 545.11, "dur": 0.98, "end": 546.09, "text": "I don&#39;t like the term."}, {"index": 163, "start": 546.09, "dur": 1.69, "end": 547.78, "text": "It&#39;s called convolution."}, {"index": 164, "start": 547.78, "dur": 3.51, "end": 551.29, "text": "I don&#39;t like the term because\nin the second-best course"}, {"index": 165, "start": 551.29, "dur": 1.689, "end": 552.979, "text": "at the Institute,\nSignals and Systems,"}, {"index": 166, "start": 552.979, "dur": 2.041, "end": 555.02, "text": "you learn about impulse\nresponses and convolution"}, {"index": 167, "start": 555.02, "dur": 1.79, "end": 556.81, "text": "integrals and stuff like that."}, {"index": 168, "start": 556.81, "dur": 2.69, "end": 559.5, "text": "And this hints at that,\nbut it&#39;s not the same thing"}, {"index": 169, "start": 559.5, "dur": 3.43, "end": 562.93, "text": "because there&#39;s no memory\ninvolved in what&#39;s going on"}, {"index": 170, "start": 562.93, "dur": 1.63, "end": 564.56, "text": "as these signals are processed."}, {"index": 171, "start": 564.56, "dur": 2.914, "end": 567.474, "text": "But they call it convolutional\nneural nets anyway."}, {"index": 172, "start": 567.474, "dur": 0.666, "end": 568.14, "text": "So here you are."}, {"index": 173, "start": 568.14, "dur": 1.593, "end": 569.733, "text": "You got some kind of image."}, {"index": 174, "start": 569.733, "dur": 2.557, "end": 572.29}, {"index": 175, "start": 572.29, "dur": 5.33, "end": 577.62, "text": "And even with lots of computing\npower and GPUs and all"}, {"index": 176, "start": 577.62, "dur": 2.35, "end": 579.97, "text": "that sort of stuff, we&#39;re\nnot talking about images"}, {"index": 177, "start": 579.97, "dur": 2.66, "end": 582.63, "text": "with 4 million pixels."}, {"index": 178, "start": 582.63, "dur": 3.46, "end": 586.09, "text": "We&#39;re talking about images\nthat might be 256 on a side."}, {"index": 179, "start": 586.09, "dur": 7.194, "end": 593.284}, {"index": 180, "start": 593.284, "dur": 1.666, "end": 594.95, "text": "As I say, we&#39;re not\ntalking about images"}, {"index": 181, "start": 594.95, "dur": 3.3, "end": 598.25, "text": "that are 1,000 by 1,000 or 4,000\nby 4,000 or anything like that."}, {"index": 182, "start": 598.25, "dur": 2.69, "end": 600.94, "text": "They tend to be\nkind of compressed"}, {"index": 183, "start": 600.94, "dur": 3.6, "end": 604.54, "text": "into a 256-by-256 image."}, {"index": 184, "start": 604.54, "dur": 4.64, "end": 609.18, "text": "And now what we do\nis we run over this"}, {"index": 185, "start": 609.18, "dur": 3.09, "end": 612.27, "text": "with a neuron that\nis looking only"}, {"index": 186, "start": 612.27, "dur": 10.71, "end": 622.98, "text": "at a 10-by-10 square like so,\nand that produces an output."}, {"index": 187, "start": 622.98, "dur": 4.11, "end": 627.09, "text": "And next, we went\nover that again having"}, {"index": 188, "start": 627.09, "dur": 5.18, "end": 632.27, "text": "shifted this neuron\na little bit like so."}, {"index": 189, "start": 632.27, "dur": 4.68, "end": 636.95, "text": "And then the next thing we do\nis we shift it again, so we"}, {"index": 190, "start": 636.95, "dur": 2.92, "end": 639.87, "text": "get that output right there."}, {"index": 191, "start": 639.87, "dur": 6.32, "end": 646.19, "text": "So each of those deployments\nof a neuron produces an output,"}, {"index": 192, "start": 646.19, "dur": 2.64, "end": 648.83, "text": "and that output is associated\nwith a particular place"}, {"index": 193, "start": 648.83, "dur": 1.7, "end": 650.53, "text": "in the image."}, {"index": 194, "start": 650.53, "dur": 7.53, "end": 658.06, "text": "This is the process that\nis called convolution"}, {"index": 195, "start": 658.06, "dur": 1.51, "end": 659.57, "text": "as a term of art."}, {"index": 196, "start": 659.57, "dur": 4.59, "end": 664.16, "text": "Now, this guy, or this\nconvolution operation,"}, {"index": 197, "start": 664.16, "dur": 1.88, "end": 666.04, "text": "results in a bunch\nof points over here."}, {"index": 198, "start": 666.04, "dur": 6.344, "end": 672.384}, {"index": 199, "start": 672.384, "dur": 4.346, "end": 676.73, "text": "And the next thing that\nwe do with those points"}, {"index": 200, "start": 676.73, "dur": 2.48, "end": 679.21, "text": "is we look in\nlocal neighborhoods"}, {"index": 201, "start": 679.21, "dur": 3.13, "end": 682.34, "text": "and see what the\nmaximum value is."}, {"index": 202, "start": 682.34, "dur": 2.31, "end": 684.65, "text": "And then we take\nthat maximum value"}, {"index": 203, "start": 684.65, "dur": 3.35, "end": 688, "text": "and construct yet another\nmapping of the image"}, {"index": 204, "start": 688, "dur": 3.03, "end": 691.03, "text": "over here using\nthat maximum value."}, {"index": 205, "start": 691.03, "dur": 5.44, "end": 696.47, "text": "Then we slide that over like so,\nand we produce another value."}, {"index": 206, "start": 696.47, "dur": 4.4, "end": 700.87, "text": "And then we slide\nthat over one more"}, {"index": 207, "start": 700.87, "dur": 3.53, "end": 704.4, "text": "time with a different\ncolor, and now we&#39;ve"}, {"index": 208, "start": 704.4, "dur": 2.23, "end": 706.63, "text": "got yet another value."}, {"index": 209, "start": 706.63, "dur": 1.602, "end": 708.232, "text": "So this process\nis called pooling."}, {"index": 210, "start": 708.232, "dur": 6.737, "end": 714.969}, {"index": 211, "start": 714.969, "dur": 1.541, "end": 716.51, "text": "And because we&#39;re\ntaking the maximum,"}, {"index": 212, "start": 716.51, "dur": 4.45, "end": 720.96, "text": "this particular kind of\npooling is called max pooling."}, {"index": 213, "start": 720.96, "dur": 2.24, "end": 723.2, "text": "So now let&#39;s see what&#39;s next."}, {"index": 214, "start": 723.2, "dur": 2.36, "end": 725.56, "text": "This is taking a\nparticular neuron"}, {"index": 215, "start": 725.56, "dur": 3.31, "end": 728.87, "text": "and running it across the image."}, {"index": 216, "start": 728.87, "dur": 4.1, "end": 732.97, "text": "We call that a kernel, again\nsucking some terminology out"}, {"index": 217, "start": 732.97, "dur": 1.166, "end": 734.136, "text": "of Signals and Systems."}, {"index": 218, "start": 734.136, "dur": 1.374, "end": 735.51, "text": "But now what we&#39;re\ngoing to do is"}, {"index": 219, "start": 735.51, "dur": 3.63, "end": 739.14, "text": "we&#39;re going to say we could\nuse a whole bunch of kernels."}, {"index": 220, "start": 739.14, "dur": 2.85, "end": 741.99, "text": "So the thing that I\nproduce with one kernel"}, {"index": 221, "start": 741.99, "dur": 5.44, "end": 747.43, "text": "can now be repeated\nmany times like so."}, {"index": 222, "start": 747.43, "dur": 3.44, "end": 750.87, "text": "In fact, a typical\nnumber is 100 times."}, {"index": 223, "start": 750.87, "dur": 3.57, "end": 754.44, "text": "So now what we&#39;ve got is\nwe&#39;ve got a 256-by-256 image."}, {"index": 224, "start": 754.44, "dur": 3.8, "end": 758.24, "text": "We&#39;ve gone over it\nwith a 10-by-10 kernel."}, {"index": 225, "start": 758.24, "dur": 3.52, "end": 761.76, "text": "We have taken the\nmaximum values that"}, {"index": 226, "start": 761.76, "dur": 1.99, "end": 763.75, "text": "are in the vicinity\nof each other,"}, {"index": 227, "start": 763.75, "dur": 4.52, "end": 768.27, "text": "and then we repeated\nthat 100 times."}, {"index": 228, "start": 768.27, "dur": 5.05, "end": 773.32, "text": "So now we can take that, and\nwe can feed all those results"}, {"index": 229, "start": 773.32, "dur": 2.22, "end": 775.54, "text": "into some kind of neural net."}, {"index": 230, "start": 775.54, "dur": 3.67, "end": 779.21, "text": "And then we can, through\nperhaps a fully-connected job"}, {"index": 231, "start": 779.21, "dur": 4.8, "end": 784.01, "text": "on the final layers of this, and\nthen in the ultimate output we"}, {"index": 232, "start": 784.01, "dur": 3.76, "end": 787.77, "text": "get some sort of\nindication of how likely it"}, {"index": 233, "start": 787.77, "dur": 3.89, "end": 791.66, "text": "is that the thing that&#39;s\nbeing seen is, say, a mite."}, {"index": 234, "start": 791.66, "dur": 3.64, "end": 795.3}, {"index": 235, "start": 795.3, "dur": 5.55, "end": 800.85, "text": "So that&#39;s roughly how\nthese things work."}, {"index": 236, "start": 800.85, "dur": 1.68, "end": 802.53, "text": "So what have we\ntalked about so far?"}, {"index": 237, "start": 802.53, "dur": 5.25, "end": 807.78, "text": "We&#39;ve talked about pooling, and\nwe&#39;ve talked about convolution."}, {"index": 238, "start": 807.78, "dur": 3.67, "end": 811.45, "text": "And now we can talk about\nsome of the good stuff."}, {"index": 239, "start": 811.45, "dur": 3.725, "end": 815.175, "text": "But before I get into that,\nthis is what we can do now,"}, {"index": 240, "start": 815.175, "dur": 2.833, "end": 818.008, "text": "and you can compare this with\nwhat was done in the old days."}, {"index": 241, "start": 818.008, "dur": 4.622, "end": 822.63}, {"index": 242, "start": 822.63, "dur": 2.41, "end": 825.04, "text": "It was done in the old\ndays before massive amounts"}, {"index": 243, "start": 825.04, "dur": 11.03, "end": 836.07, "text": "of computing became available\nis a kind of neural net activity"}, {"index": 244, "start": 836.07, "dur": 2.28, "end": 838.35, "text": "that&#39;s a little easier to see."}, {"index": 245, "start": 838.35, "dur": 4.74, "end": 843.09, "text": "You might, in the old days,\nonly have enough computing power"}, {"index": 246, "start": 843.09, "dur": 2.65, "end": 845.74, "text": "to deal with a small\ngrid of picture elements,"}, {"index": 247, "start": 845.74, "dur": 1.74, "end": 847.48, "text": "or so-called pixels."}, {"index": 248, "start": 847.48, "dur": 5.41, "end": 852.89, "text": "And then each of these might be\na value that is fed as an input"}, {"index": 249, "start": 852.89, "dur": 2.11, "end": 855, "text": "into some kind of neuron."}, {"index": 250, "start": 855, "dur": 4.11, "end": 859.11, "text": "And so you might have a column\nof neurons that are looking"}, {"index": 251, "start": 859.11, "dur": 4.75, "end": 863.86, "text": "at these pixels in your image."}, {"index": 252, "start": 863.86, "dur": 2.55, "end": 866.41, "text": "And then there might be\na small number of columns"}, {"index": 253, "start": 866.41, "dur": 1.42, "end": 867.83, "text": "that follow from that."}, {"index": 254, "start": 867.83, "dur": 2.95, "end": 870.78, "text": "And finally, something\nthat says this neuron"}, {"index": 255, "start": 870.78, "dur": 5.04, "end": 875.82, "text": "is looking for things that are\na number 1, that is to say,"}, {"index": 256, "start": 875.82, "dur": 7.51, "end": 883.33, "text": "something that looks like\na number 1 in the image."}, {"index": 257, "start": 883.33, "dur": 3.1, "end": 886.43, "text": "So this stuff up\nhere is what you"}, {"index": 258, "start": 886.43, "dur": 2.167, "end": 888.597, "text": "can do when you have a\nmassive amount of computation"}, {"index": 259, "start": 888.597, "dur": 1.374, "end": 889.971, "text": "relative to the\nkind of thing you"}, {"index": 260, "start": 889.971, "dur": 1.269, "end": 891.24, "text": "used to see in the old days."}, {"index": 261, "start": 891.24, "dur": 4.16, "end": 895.4}, {"index": 262, "start": 895.4, "dur": 2.606, "end": 898.006, "text": "So what&#39;s different?"}, {"index": 263, "start": 898.006, "dur": 1.374, "end": 899.38, "text": "Well, what&#39;s\ndifferent is instead"}, {"index": 264, "start": 899.38, "dur": 3.35, "end": 902.73, "text": "of a few hundred parameters,\nwe&#39;ve got a lot more."}, {"index": 265, "start": 902.73, "dur": 4.27, "end": 907, "text": "Instead of 10 digits,\nwe have 1,000 classes."}, {"index": 266, "start": 907, "dur": 2.13, "end": 909.13, "text": "Instead of a few\nhundred samples,"}, {"index": 267, "start": 909.13, "dur": 4.44, "end": 913.57, "text": "we have maybe 1,000\nexamples of each class."}, {"index": 268, "start": 913.57, "dur": 2.7, "end": 916.27, "text": "So that makes a million samples."}, {"index": 269, "start": 916.27, "dur": 3.76, "end": 920.03, "text": "And we got 60 million\nparameters to play with."}, {"index": 270, "start": 920.03, "dur": 3.03, "end": 923.06, "text": "And the surprising thing\nis that the net result"}, {"index": 271, "start": 923.06, "dur": 3.74, "end": 926.8, "text": "is we&#39;ve got a function\napproximator that"}, {"index": 272, "start": 926.8, "dur": 1.58, "end": 928.38, "text": "astonishes everybody."}, {"index": 273, "start": 928.38, "dur": 1.69, "end": 930.07, "text": "And no one quite\nknows why it works,"}, {"index": 274, "start": 930.07, "dur": 4.16, "end": 934.23, "text": "except that when you throw an\nimmense amount of computation"}, {"index": 275, "start": 934.23, "dur": 4.12, "end": 938.35, "text": "into this kind of\narrangement, it&#39;s"}, {"index": 276, "start": 938.35, "dur": 4.42, "end": 942.77, "text": "possible to get a performance\nthat no one expected would"}, {"index": 277, "start": 942.77, "dur": 2.77, "end": 945.54, "text": "be possible."}, {"index": 278, "start": 945.54, "dur": 1.63, "end": 947.17, "text": "So that&#39;s sort of\nthe bottom line."}, {"index": 279, "start": 947.17, "dur": 4.07, "end": 951.24, "text": "But now there are a couple of\nideas beyond that that I think"}, {"index": 280, "start": 951.24, "dur": 4.79, "end": 956.03, "text": "are especially interesting,\nand I want to talk about those."}, {"index": 281, "start": 956.03, "dur": 2.66, "end": 958.69, "text": "First idea that&#39;s\nespecially interesting"}, {"index": 282, "start": 958.69, "dur": 3.04, "end": 961.73, "text": "is the idea of\nautocoding, and here&#39;s"}, {"index": 283, "start": 961.73, "dur": 1.8, "end": 963.53, "text": "how the idea of\nautocoding works."}, {"index": 284, "start": 963.53, "dur": 5.66, "end": 969.19}, {"index": 285, "start": 969.19, "dur": 1.5, "end": 970.69, "text": "I&#39;m going to run\nout of board space,"}, {"index": 286, "start": 970.69, "dur": 3.54, "end": 974.23, "text": "so I think I&#39;ll\ndo it right here."}, {"index": 287, "start": 974.23, "dur": 2.09, "end": 976.32, "text": "You have some input values."}, {"index": 288, "start": 976.32, "dur": 8.54, "end": 984.86}, {"index": 289, "start": 984.86, "dur": 4.56, "end": 989.42, "text": "They go into a layer of\nneurons, the input layer."}, {"index": 290, "start": 989.42, "dur": 3.761, "end": 993.181, "text": "Then there is a so-called hidden\nlayer that&#39;s much smaller."}, {"index": 291, "start": 993.181, "dur": 2.829, "end": 996.01}, {"index": 292, "start": 996.01, "dur": 3.82, "end": 999.83, "text": "So maybe in the example,\nthere will be 10 neurons here"}, {"index": 293, "start": 999.83, "dur": 1.98, "end": 1001.81, "text": "and just a couple here."}, {"index": 294, "start": 1001.81, "dur": 5.94, "end": 1007.75, "text": "And then these expand to\nan output layer like so."}, {"index": 295, "start": 1007.75, "dur": 5.43, "end": 1013.18, "text": "Now we can take the output\nlayer, z1 through zn,"}, {"index": 296, "start": 1013.18, "dur": 5.85, "end": 1019.03, "text": "and compare it with the\ndesired values, d1 through dn."}, {"index": 297, "start": 1019.03, "dur": 2.89, "end": 1021.92}, {"index": 298, "start": 1021.92, "dur": 1.85, "end": 1023.77, "text": "You following me so far?"}, {"index": 299, "start": 1023.77, "dur": 5.25, "end": 1029.02, "text": "Now, the trick is to say, well,\nwhat are the desired values?"}, {"index": 300, "start": 1029.02, "dur": 4.585, "end": 1033.605, "text": "Let&#39;s let the desired\nvalues be the input values."}, {"index": 301, "start": 1033.605, "dur": 3.649, "end": 1037.254}, {"index": 302, "start": 1037.254, "dur": 1.416, "end": 1038.6699999999998, "text": "So what we&#39;re going\nto do is we&#39;re"}, {"index": 303, "start": 1038.67, "dur": 2.169, "end": 1040.8390000000002, "text": "going to train this net\nup so that the output&#39;s"}, {"index": 304, "start": 1040.839, "dur": 2.761, "end": 1043.6, "text": "the same as the input."}, {"index": 305, "start": 1043.6, "dur": 0.999, "end": 1044.599, "text": "What&#39;s the good of that?"}, {"index": 306, "start": 1044.599, "dur": 2.431, "end": 1047.03, "text": "Well, we&#39;re going to\nforce it down through this"}, {"index": 307, "start": 1047.03, "dur": 3.24, "end": 1050.27, "text": "[? neck-down ?]\npiece of network."}, {"index": 308, "start": 1050.27, "dur": 3.37, "end": 1053.64, "text": "So if this network\nis going to succeed"}, {"index": 309, "start": 1053.64, "dur": 3.52, "end": 1057.16, "text": "in taking all the possibilities\nhere and cramming them"}, {"index": 310, "start": 1057.16, "dur": 5.56, "end": 1062.72, "text": "into this smaller inner layer,\nthe so-called hidden layer,"}, {"index": 311, "start": 1062.72, "dur": 3.18, "end": 1065.9, "text": "such that it can reproduce\nthe input [? at ?] the output,"}, {"index": 312, "start": 1065.9, "dur": 2.4, "end": 1068.3, "text": "it must be doing some\nkind of generalization"}, {"index": 313, "start": 1068.3, "dur": 4.26, "end": 1072.56, "text": "of the kinds of things\nit sees on its input."}, {"index": 314, "start": 1072.56, "dur": 4.27, "end": 1076.83, "text": "And that&#39;s a very clever idea,\nand it&#39;s seen in various forms"}, {"index": 315, "start": 1076.83, "dur": 3.37, "end": 1080.2, "text": "in a large fraction\nof the papers that"}, {"index": 316, "start": 1080.2, "dur": 3.14, "end": 1083.34, "text": "appear on deep neural nets."}, {"index": 317, "start": 1083.34, "dur": 2.044, "end": 1085.384, "text": "But now I want to\ntalk about an example"}, {"index": 318, "start": 1085.384, "dur": 1.416, "end": 1086.8, "text": "so I can show you\na demonstration."}, {"index": 319, "start": 1086.8, "dur": 1.06, "end": 1087.86, "text": "OK?"}, {"index": 320, "start": 1087.86, "dur": 3.55, "end": 1091.41, "text": "So we don&#39;t have GPUs, and\nwe don&#39;t have three days"}, {"index": 321, "start": 1091.41, "dur": 1.26, "end": 1092.67, "text": "to do this."}, {"index": 322, "start": 1092.67, "dur": 4.85, "end": 1097.52, "text": "So I&#39;m going to make up a\nvery simple example that&#39;s"}, {"index": 323, "start": 1097.52, "dur": 3.49, "end": 1101.01, "text": "reminiscent of what goes\non here but involves"}, {"index": 324, "start": 1101.01, "dur": 1.964, "end": 1102.974, "text": "hardly any computation."}, {"index": 325, "start": 1102.974, "dur": 1.416, "end": 1104.39, "text": "What I&#39;m going to\nimagine is we&#39;re"}, {"index": 326, "start": 1104.39, "dur": 6.87, "end": 1111.26, "text": "trying to recognize\nanimals from how tall they"}, {"index": 327, "start": 1111.26, "dur": 4.66, "end": 1115.92, "text": "are from the shadows\nthat they cast."}, {"index": 328, "start": 1115.92, "dur": 8.02, "end": 1123.94, "text": "So we&#39;re going to recognize\nthree animals, a cheetah,"}, {"index": 329, "start": 1123.94, "dur": 7.12, "end": 1131.06, "text": "a zebra, and a giraffe, and\nthey will each cast a shadow"}, {"index": 330, "start": 1131.06, "dur": 4.74, "end": 1135.8, "text": "on the blackboard like me."}, {"index": 331, "start": 1135.8, "dur": 1.212, "end": 1137.012, "text": "No vampire involved here."}, {"index": 332, "start": 1137.012, "dur": 1.458, "end": 1138.47, "text": "And what we&#39;re\ngoing to do is we&#39;re"}, {"index": 333, "start": 1138.47, "dur": 4.82, "end": 1143.29, "text": "going to use the shadow as\nan input to a neural net."}, {"index": 334, "start": 1143.29, "dur": 0.686, "end": 1143.976, "text": "All right?"}, {"index": 335, "start": 1143.976, "dur": 1.374, "end": 1145.35, "text": "So let&#39;s see how\nthat would work."}, {"index": 336, "start": 1145.35, "dur": 14, "end": 1159.35}, {"index": 337, "start": 1159.35, "dur": 4.83, "end": 1164.18, "text": "So there is our network."}, {"index": 338, "start": 1164.18, "dur": 2.3, "end": 1166.48, "text": "And if I just clicked into\none of these test samples,"}, {"index": 339, "start": 1166.48, "dur": 5.53, "end": 1172.01, "text": "that&#39;s the height of the shadow\nthat a cheetah casts on a wall."}, {"index": 340, "start": 1172.01, "dur": 2.89, "end": 1174.9, "text": "And there are 10 input\nneurons corresponding"}, {"index": 341, "start": 1174.9, "dur": 2.6, "end": 1177.5, "text": "to each level of the shadow."}, {"index": 342, "start": 1177.5, "dur": 3.85, "end": 1181.35, "text": "They&#39;re rammed through\nthree inner layer neurons,"}, {"index": 343, "start": 1181.35, "dur": 4.817, "end": 1186.167, "text": "and from that it spreads out and\nbecomes the outer layer values."}, {"index": 344, "start": 1186.167, "dur": 1.833, "end": 1188, "text": "And we&#39;re going to\ncompare those outer layer"}, {"index": 345, "start": 1188, "dur": 2.52, "end": 1190.52, "text": "values to the desired values,\nbut the desired values"}, {"index": 346, "start": 1190.52, "dur": 2.12, "end": 1192.64, "text": "are the same as\nthe input values."}, {"index": 347, "start": 1192.64, "dur": 2.2, "end": 1194.84, "text": "So this column is a\ncolumn of input values."}, {"index": 348, "start": 1194.84, "dur": 3.58, "end": 1198.42, "text": "On the far right, we have\nour column of desired values."}, {"index": 349, "start": 1198.42, "dur": 2.23, "end": 1200.65, "text": "And we haven&#39;t trained\nthis neural net yet."}, {"index": 350, "start": 1200.65, "dur": 2.25, "end": 1202.9, "text": "All we&#39;ve got is\nrandom values in there."}, {"index": 351, "start": 1202.9, "dur": 5.24, "end": 1208.14, "text": "So if we run the test samples\nthrough, we get that and that."}, {"index": 352, "start": 1208.14, "dur": 3.26, "end": 1211.4, "text": "Yeah, cheetahs are short,\nzebras are medium height,"}, {"index": 353, "start": 1211.4, "dur": 1.74, "end": 1213.14, "text": "and giraffes are tall."}, {"index": 354, "start": 1213.14, "dur": 6.49, "end": 1219.63, "text": "But our output is just pretty\nmuch 0.5 for all of them,"}, {"index": 355, "start": 1219.63, "dur": 1.84, "end": 1221.47, "text": "for all of those shadow\nheights, all right,"}, {"index": 356, "start": 1221.47, "dur": 2.64, "end": 1224.11, "text": "[? with ?] no training so far."}, {"index": 357, "start": 1224.11, "dur": 1.16, "end": 1225.27, "text": "So let&#39;s run this thing."}, {"index": 358, "start": 1225.27, "dur": 2.54, "end": 1227.81, "text": "We&#39;re just using simple\n[? backdrop, ?] just like on"}, {"index": 359, "start": 1227.81, "dur": 2.76, "end": 1230.57, "text": "our world&#39;s simplest neural net."}, {"index": 360, "start": 1230.57, "dur": 6.13, "end": 1236.7, "text": "And it&#39;s interesting\nto see what happens."}, {"index": 361, "start": 1236.7, "dur": 1.61, "end": 1238.31, "text": "You see all those\nvalues changing?"}, {"index": 362, "start": 1238.31, "dur": 3.7, "end": 1242.01, "text": "Now, I need to mention that\nwhen you see a green connection,"}, {"index": 363, "start": 1242.01, "dur": 2.38, "end": 1244.39, "text": "that means it&#39;s a\npositive weight,"}, {"index": 364, "start": 1244.39, "dur": 5.48, "end": 1249.87, "text": "and the density of the green\nindicates how positive it is."}, {"index": 365, "start": 1249.87, "dur": 1.99, "end": 1251.86, "text": "And the red ones are\nnegative weights,"}, {"index": 366, "start": 1251.86, "dur": 3.14, "end": 1255, "text": "and the intensity of the\nred indicates how red it is."}, {"index": 367, "start": 1255, "dur": 1.59, "end": 1256.59, "text": "So here you can\nsee that we still"}, {"index": 368, "start": 1256.59, "dur": 3.04, "end": 1259.63, "text": "have from our random\ninputs a variety"}, {"index": 369, "start": 1259.63, "dur": 1.32, "end": 1260.95, "text": "of red and green values."}, {"index": 370, "start": 1260.95, "dur": 1.73, "end": 1262.68, "text": "We haven&#39;t really\ndone much training,"}, {"index": 371, "start": 1262.68, "dur": 4.16, "end": 1266.84, "text": "so everything correctly\nlooks pretty much random."}, {"index": 372, "start": 1266.84, "dur": 3.32, "end": 1270.16, "text": "So let&#39;s run this thing."}, {"index": 373, "start": 1270.16, "dur": 7.084, "end": 1277.244, "text": "And after only 1,000 iterations\ngoing through these examples"}, {"index": 374, "start": 1277.244, "dur": 2.166, "end": 1279.41, "text": "and trying to make the\noutput the same as the input,"}, {"index": 375, "start": 1279.41, "dur": 2.764, "end": 1282.174, "text": "we reached a point where\nthe error rate has dropped."}, {"index": 376, "start": 1282.174, "dur": 1.416, "end": 1283.59, "text": "In fact, it&#39;s\ndropped so much it&#39;s"}, {"index": 377, "start": 1283.59, "dur": 3.32, "end": 1286.91, "text": "interesting to relook\nat the test cases."}, {"index": 378, "start": 1286.91, "dur": 2.24, "end": 1289.15, "text": "So here&#39;s a test case\nwhere we have a cheetah."}, {"index": 379, "start": 1289.15, "dur": 1.83, "end": 1290.98, "text": "And now the output\nvalue is, in fact,"}, {"index": 380, "start": 1290.98, "dur": 6.76, "end": 1297.74, "text": "very close to the desired value\nin all the output neurons."}, {"index": 381, "start": 1297.74, "dur": 2.94, "end": 1300.68, "text": "So if we look at\nanother one, once again,"}, {"index": 382, "start": 1300.68, "dur": 3.1, "end": 1303.78, "text": "there&#39;s a correspondence\nin the right two columns."}, {"index": 383, "start": 1303.78, "dur": 2.165, "end": 1305.945, "text": "And if we look at the\nfinal one, yeah, there&#39;s"}, {"index": 384, "start": 1305.945, "dur": 1.75, "end": 1307.695, "text": "a correspondence in\nthe right two columns."}, {"index": 385, "start": 1307.695, "dur": 3.285, "end": 1310.98}, {"index": 386, "start": 1310.98, "dur": 1.95, "end": 1312.93, "text": "Now, you back up from\nthis and say, well,"}, {"index": 387, "start": 1312.93, "dur": 2.64, "end": 1315.57, "text": "what&#39;s going on here?"}, {"index": 388, "start": 1315.57, "dur": 4.75, "end": 1320.32, "text": "It turns out that you&#39;re\nnot training this thing"}, {"index": 389, "start": 1320.32, "dur": 2.17, "end": 1322.49, "text": "to classify animals."}, {"index": 390, "start": 1322.49, "dur": 3.1, "end": 1325.59, "text": "You&#39;re training it to understand\nthe nature of the things"}, {"index": 391, "start": 1325.59, "dur": 3.857, "end": 1329.447, "text": "that it sees in the\nenvironment because all it sees"}, {"index": 392, "start": 1329.447, "dur": 1.083, "end": 1330.53, "text": "is the height of a shadow."}, {"index": 393, "start": 1330.53, "dur": 2.083, "end": 1332.613, "text": "It doesn&#39;t know anything\nabout the classifications"}, {"index": 394, "start": 1332.613, "dur": 1.997, "end": 1334.61, "text": "you&#39;re going to try\nto get out of that."}, {"index": 395, "start": 1334.61, "dur": 2.86, "end": 1337.47, "text": "All it sees is that there&#39;s\na kind of consistency"}, {"index": 396, "start": 1337.47, "dur": 4.16, "end": 1341.63, "text": "in the kind of data that it\nsees on the input values."}, {"index": 397, "start": 1341.63, "dur": 1.54, "end": 1343.17, "text": "Right?"}, {"index": 398, "start": 1343.17, "dur": 1.69, "end": 1344.86, "text": "Now, you might say,\nOK, oh, that&#39;s cool,"}, {"index": 399, "start": 1344.86, "dur": 1.75, "end": 1346.61, "text": "because what must\nbe happening is"}, {"index": 400, "start": 1346.61, "dur": 3.12, "end": 1349.73, "text": "that that hidden layer,\nbecause everything is forced"}, {"index": 401, "start": 1349.73, "dur": 2.39, "end": 1352.12, "text": "through that narrow\npipe, must be doing"}, {"index": 402, "start": 1352.12, "dur": 3.109, "end": 1355.229, "text": "some kind of generalization."}, {"index": 403, "start": 1355.229, "dur": 1.791, "end": 1357.02, "text": "So it ought to be the\ncase that if we click"}, {"index": 404, "start": 1357.02, "dur": 1.416, "end": 1358.436, "text": "on each of those\nneurons, we ought"}, {"index": 405, "start": 1358.436, "dur": 2.384, "end": 1360.82, "text": "to see it specialize\nto a particular height,"}, {"index": 406, "start": 1360.82, "dur": 5.47, "end": 1366.29, "text": "because that&#39;s the sort of stuff\nthat&#39;s presented on the input."}, {"index": 407, "start": 1366.29, "dur": 2.88, "end": 1369.17, "text": "Well, let&#39;s go see\nwhat, in fact, is"}, {"index": 408, "start": 1369.17, "dur": 3.81, "end": 1372.98, "text": "the maximum\nstimulation to be seen"}, {"index": 409, "start": 1372.98, "dur": 3.56, "end": 1376.54, "text": "on the neurons in\nthat hidden layer."}, {"index": 410, "start": 1376.54, "dur": 3.32, "end": 1379.86, "text": "So when I click on these\nguys, what we&#39;re going to see"}, {"index": 411, "start": 1379.86, "dur": 3.13, "end": 1382.99, "text": "is the input values\nthat maximally"}, {"index": 412, "start": 1382.99, "dur": 2.184, "end": 1385.174, "text": "stimulate that neuron."}, {"index": 413, "start": 1385.174, "dur": 1.416, "end": 1386.59, "text": "And by the way, I\nhave no idea how"}, {"index": 414, "start": 1386.59, "dur": 2.89, "end": 1389.48, "text": "this is going to turn out\nbecause the initialization&#39;s"}, {"index": 415, "start": 1389.48, "dur": 2.1, "end": 1391.58, "text": "all random."}, {"index": 416, "start": 1391.58, "dur": 0.78, "end": 1392.36, "text": "Well, that&#39;s good."}, {"index": 417, "start": 1392.36, "dur": 1.5, "end": 1393.86, "text": "That one looks like\nit&#39;s generalized"}, {"index": 418, "start": 1393.86, "dur": 3.06, "end": 1396.92, "text": "the notion of short."}, {"index": 419, "start": 1396.92, "dur": 3.77, "end": 1400.69, "text": "Ugh, that doesn&#39;t\nlook like medium."}, {"index": 420, "start": 1400.69, "dur": 3.98, "end": 1404.67, "text": "And in fact, the\nmaximum stimulation"}, {"index": 421, "start": 1404.67, "dur": 3.9, "end": 1408.57, "text": "doesn&#39;t involve any stimulation\nfrom that lower neuron."}, {"index": 422, "start": 1408.57, "dur": 2.6, "end": 1411.17, "text": "Here, look at this one."}, {"index": 423, "start": 1411.17, "dur": 1.47, "end": 1412.64, "text": "That doesn&#39;t look like tall."}, {"index": 424, "start": 1412.64, "dur": 2.27, "end": 1414.91, "text": "So we got one that looks\nlike short and two that"}, {"index": 425, "start": 1414.91, "dur": 2.595, "end": 1417.505, "text": "just look completely random."}, {"index": 426, "start": 1417.505, "dur": 2.815, "end": 1420.32}, {"index": 427, "start": 1420.32, "dur": 2.19, "end": 1422.51, "text": "So in fact, maybe we\nbetter back off the idea"}, {"index": 428, "start": 1422.51, "dur": 2.22, "end": 1424.73, "text": "that what&#39;s going on\nin that hidden layer"}, {"index": 429, "start": 1424.73, "dur": 4.12, "end": 1428.85, "text": "is generalization\nand say that what"}, {"index": 430, "start": 1428.85, "dur": 2.81, "end": 1431.66, "text": "is going on in there\nis maybe the encoding"}, {"index": 431, "start": 1431.66, "dur": 2.18, "end": 1433.84, "text": "of a generalization."}, {"index": 432, "start": 1433.84, "dur": 2.35, "end": 1436.19, "text": "It doesn&#39;t look like\nan encoding we can see,"}, {"index": 433, "start": 1436.19, "dur": 4.87, "end": 1441.06, "text": "but there is a generalization\nthat&#39;s-- let me start that"}, {"index": 434, "start": 1441.06, "dur": 0.76, "end": 1441.82, "text": "over."}, {"index": 435, "start": 1441.82, "dur": 6.492, "end": 1448.312, "text": "We don&#39;t see the generalization\nin the stimulating values."}, {"index": 436, "start": 1448.312, "dur": 1.708, "end": 1450.02, "text": "What we have instead\nis we have some kind"}, {"index": 437, "start": 1450.02, "dur": 2.547, "end": 1452.567, "text": "of encoded generalization."}, {"index": 438, "start": 1452.567, "dur": 1.583, "end": 1454.15, "text": "And because we got\nthis stuff encoded,"}, {"index": 439, "start": 1454.15, "dur": 2.42, "end": 1456.57, "text": "it&#39;s what makes these neural\nnets so extraordinarily"}, {"index": 440, "start": 1456.57, "dur": 1.4, "end": 1457.97, "text": "difficult to understand."}, {"index": 441, "start": 1457.97, "dur": 2.64, "end": 1460.61, "text": "We don&#39;t understand\nwhat they&#39;re doing."}, {"index": 442, "start": 1460.61, "dur": 2.44, "end": 1463.05, "text": "We don&#39;t understand why they\ncan recognize a cheetah."}, {"index": 443, "start": 1463.05, "dur": 2.35, "end": 1465.4, "text": "We don&#39;t understand why\nit can recognize a school"}, {"index": 444, "start": 1465.4, "dur": 1.67, "end": 1467.07, "text": "bus in some cases,\nbut not in others,"}, {"index": 445, "start": 1467.07, "dur": 2.71, "end": 1469.78, "text": "because we don&#39;t\nreally understand"}, {"index": 446, "start": 1469.78, "dur": 2.75, "end": 1472.53, "text": "what these neurons\nare responding to."}, {"index": 447, "start": 1472.53, "dur": 1.58, "end": 1474.11, "text": "Well, that&#39;s not quite true."}, {"index": 448, "start": 1474.11, "dur": 2.19, "end": 1476.3, "text": "There&#39;s been a lot\nof work recently"}, {"index": 449, "start": 1476.3, "dur": 2.39, "end": 1478.69, "text": "on trying to sort that\nout, but it&#39;s still"}, {"index": 450, "start": 1478.69, "dur": 3.18, "end": 1481.87, "text": "a lot of mystery in this world."}, {"index": 451, "start": 1481.87, "dur": 2.83, "end": 1484.7, "text": "In any event, that&#39;s\nthe autocoding idea."}, {"index": 452, "start": 1484.7, "dur": 1.245, "end": 1485.945, "text": "It comes in various guises."}, {"index": 453, "start": 1485.945, "dur": 2.375, "end": 1488.32, "text": "Sometimes people talk about\nBoltzmann machines and things"}, {"index": 454, "start": 1488.32, "dur": 0.56, "end": 1488.88, "text": "of that sort."}, {"index": 455, "start": 1488.88, "dur": 2.35, "end": 1491.23, "text": "But it&#39;s basically all\nthe same sort of idea."}, {"index": 456, "start": 1491.23, "dur": 2.07, "end": 1493.3, "text": "And so what you can\ndo is layer by layer."}, {"index": 457, "start": 1493.3, "dur": 1.99, "end": 1495.29, "text": "Once you&#39;ve trained\nthe input layer,"}, {"index": 458, "start": 1495.29, "dur": 2.52, "end": 1497.81, "text": "then you can use that layer\nto train the next layer,"}, {"index": 459, "start": 1497.81, "dur": 2.3, "end": 1500.11, "text": "and then that can train\nthe next layer after that."}, {"index": 460, "start": 1500.11, "dur": 4.25, "end": 1504.36, "text": "And it&#39;s only at the very, very\nend that you say to yourself,"}, {"index": 461, "start": 1504.36, "dur": 2.36, "end": 1506.72, "text": "well, now I&#39;ve accumulated\na lot of knowledge"}, {"index": 462, "start": 1506.72, "dur": 3.5, "end": 1510.22, "text": "about the environment and what\ncan be seen in the environment."}, {"index": 463, "start": 1510.22, "dur": 2.561, "end": 1512.781, "text": "Maybe it&#39;s time to\nget around to using"}, {"index": 464, "start": 1512.781, "dur": 4.989, "end": 1517.77, "text": "some samples of particular\nclasses and train on classes."}, {"index": 465, "start": 1517.77, "dur": 1.55, "end": 1519.32, "text": "So that&#39;s the story\non autocoding."}, {"index": 466, "start": 1519.32, "dur": 3.46, "end": 1522.78}, {"index": 467, "start": 1522.78, "dur": 3.95, "end": 1526.73, "text": "Now, the next thing to talk\nabout is that final layer."}, {"index": 468, "start": 1526.73, "dur": 2.93, "end": 1529.66}, {"index": 469, "start": 1529.66, "dur": 2.724, "end": 1532.384, "text": "So let&#39;s see what the final\nlayer might look like."}, {"index": 470, "start": 1532.384, "dur": 2.726, "end": 1535.11}, {"index": 471, "start": 1535.11, "dur": 4.83, "end": 1539.94, "text": "Let&#39;s see, it might\nlook like this."}, {"index": 472, "start": 1539.94, "dur": 4.997, "end": 1544.937, "text": "There&#39;s a [? summer. ?]\nThere&#39;s a minus 1 up here."}, {"index": 473, "start": 1544.937, "dur": 0.499, "end": 1545.436, "text": "No."}, {"index": 474, "start": 1545.436, "dur": 2.49, "end": 1547.926, "text": "Let&#39;s see, there&#39;s a\nminus 1 up-- [INAUDIBLE]."}, {"index": 475, "start": 1547.926, "dur": 2.784, "end": 1550.71}, {"index": 476, "start": 1550.71, "dur": 2.41, "end": 1553.12, "text": "There&#39;s a minus 1 up there."}, {"index": 477, "start": 1553.12, "dur": 2.3, "end": 1555.42, "text": "There&#39;s a multiplier here."}, {"index": 478, "start": 1555.42, "dur": 2.671, "end": 1558.091, "text": "And there&#39;s a\nthreshold value there."}, {"index": 479, "start": 1558.091, "dur": 2.859, "end": 1560.95, "text": "Now, likewise, there&#39;s some\nother input values here."}, {"index": 480, "start": 1560.95, "dur": 6.74, "end": 1567.69, "text": "Let me call this one x, and it\ngets multiplied by some weight."}, {"index": 481, "start": 1567.69, "dur": 2.81, "end": 1570.5, "text": "And then that goes into\nthe [? summer ?] as well."}, {"index": 482, "start": 1570.5, "dur": 9.04, "end": 1579.54, "text": "And that, in turn, goes into\na sigmoid that looks like so."}, {"index": 483, "start": 1579.54, "dur": 5.64, "end": 1585.18, "text": "And finally, you get an\noutput, which we&#39;ll z."}, {"index": 484, "start": 1585.18, "dur": 4.22, "end": 1589.4, "text": "So it&#39;s clear that if you\njust write out the value of z"}, {"index": 485, "start": 1589.4, "dur": 6.62, "end": 1596.02, "text": "as it depends on those inputs\nusing the formula that we"}, {"index": 486, "start": 1596.02, "dur": 2.75, "end": 1598.77, "text": "worked with last\ntime, then what you"}, {"index": 487, "start": 1598.77, "dur": 9.51, "end": 1608.28, "text": "see is that z is\nequal to 1 over 1"}, {"index": 488, "start": 1608.28, "dur": 12.938, "end": 1621.218, "text": "plus e to the minus w times\nx minus T-- plus T, I guess."}, {"index": 489, "start": 1621.218, "dur": 0.499, "end": 1621.717, "text": "Right?"}, {"index": 490, "start": 1621.717, "dur": 3.273, "end": 1624.99}, {"index": 491, "start": 1624.99, "dur": 3.2, "end": 1628.19, "text": "So that&#39;s a sigmoid\nfunction that"}, {"index": 492, "start": 1628.19, "dur": 3.2, "end": 1631.39, "text": "depends on the\nvalue of that weight"}, {"index": 493, "start": 1631.39, "dur": 2.58, "end": 1633.97, "text": "and on the value\nof that threshold."}, {"index": 494, "start": 1633.97, "dur": 6.54, "end": 1640.51, "text": "So let&#39;s look at how those\nvalues might change things."}, {"index": 495, "start": 1640.51, "dur": 3.293, "end": 1643.803, "text": "So here we have an\nordinary sigmoid."}, {"index": 496, "start": 1643.803, "dur": 2.747, "end": 1646.55}, {"index": 497, "start": 1646.55, "dur": 4.84, "end": 1651.39, "text": "And what happens if we shift\nit with a threshold value?"}, {"index": 498, "start": 1651.39, "dur": 3.13, "end": 1654.52, "text": "If we change that\nthreshold value,"}, {"index": 499, "start": 1654.52, "dur": 1.87, "end": 1656.39, "text": "then it&#39;s going\nto shift the place"}, {"index": 500, "start": 1656.39, "dur": 5.558, "end": 1661.948, "text": "where that sigmoid comes down."}, {"index": 501, "start": 1661.948, "dur": 3.652, "end": 1665.6}, {"index": 502, "start": 1665.6, "dur": 2.26, "end": 1667.86, "text": "So a change in T\ncould cause this thing"}, {"index": 503, "start": 1667.86, "dur": 2.91, "end": 1670.77, "text": "to shift over that way."}, {"index": 504, "start": 1670.77, "dur": 2.24, "end": 1673.01, "text": "And if we change\nthe value of w, that"}, {"index": 505, "start": 1673.01, "dur": 1.86, "end": 1674.87, "text": "could change how\nsteep this guy is."}, {"index": 506, "start": 1674.87, "dur": 3.59, "end": 1678.46}, {"index": 507, "start": 1678.46, "dur": 4.24, "end": 1682.7, "text": "So we might think that the\nperformance, since it depends"}, {"index": 508, "start": 1682.7, "dur": 6.12, "end": 1688.82, "text": "on w and T, should be\nadjusted in such a way"}, {"index": 509, "start": 1688.82, "dur": 5.65, "end": 1694.47, "text": "as to make the classification\ndo the right thing."}, {"index": 510, "start": 1694.47, "dur": 2.55, "end": 1697.02, "text": "But what&#39;s the right thing?"}, {"index": 511, "start": 1697.02, "dur": 2.377, "end": 1699.397, "text": "Well, that depends on the\nsamples that we&#39;ve seen."}, {"index": 512, "start": 1699.397, "dur": 5.093, "end": 1704.49}, {"index": 513, "start": 1704.49, "dur": 4.113, "end": 1708.603, "text": "Suppose, for example, that\nthis is our sigmoid function."}, {"index": 514, "start": 1708.603, "dur": 2.727, "end": 1711.33}, {"index": 515, "start": 1711.33, "dur": 6.05, "end": 1717.38, "text": "And we see some examples of a\nclass, some positive examples"}, {"index": 516, "start": 1717.38, "dur": 3.4, "end": 1720.78, "text": "of a class, that\nhave values that"}, {"index": 517, "start": 1720.78, "dur": 6.02, "end": 1726.8, "text": "lie at that point and\nthat point and that point."}, {"index": 518, "start": 1726.8, "dur": 7.38, "end": 1734.18, "text": "And we have some values that\ncorrespond to situations where"}, {"index": 519, "start": 1734.18, "dur": 2.86, "end": 1737.04, "text": "the class is not one of the\nthings that are associated"}, {"index": 520, "start": 1737.04, "dur": 1.54, "end": 1738.58, "text": "with this neuron."}, {"index": 521, "start": 1738.58, "dur": 3.35, "end": 1741.93, "text": "And in that case, what\nwe see is examples that"}, {"index": 522, "start": 1741.93, "dur": 1.44, "end": 1743.37, "text": "are over in this vicinity here."}, {"index": 523, "start": 1743.37, "dur": 3, "end": 1746.37}, {"index": 524, "start": 1746.37, "dur": 4.34, "end": 1750.71, "text": "So the probability that we\nwould see this particular guy"}, {"index": 525, "start": 1750.71, "dur": 4.59, "end": 1755.3, "text": "in this world is associated with\nthe value on the sigmoid curve."}, {"index": 526, "start": 1755.3, "dur": 2.12, "end": 1757.42, "text": "So you could think of\nthis as the probability"}, {"index": 527, "start": 1757.42, "dur": 1.96, "end": 1759.38, "text": "of that positive\nexample, and this"}, {"index": 528, "start": 1759.38, "dur": 2.46, "end": 1761.84, "text": "is the probability of\nthat positive example,"}, {"index": 529, "start": 1761.84, "dur": 3.18, "end": 1765.02, "text": "and this is the probability\nof that positive example."}, {"index": 530, "start": 1765.02, "dur": 3, "end": 1768.02, "text": "What&#39;s the probability\nof this negative example?"}, {"index": 531, "start": 1768.02, "dur": 4.46, "end": 1772.48, "text": "Well, it&#39;s 1 minus the\nvalue on that curve."}, {"index": 532, "start": 1772.48, "dur": 4.35, "end": 1776.83, "text": "And this one&#39;s 1 minus\nthe value on that curve."}, {"index": 533, "start": 1776.83, "dur": 2.68, "end": 1779.51, "text": "So we could go through\nthe calculations."}, {"index": 534, "start": 1779.51, "dur": 3.72, "end": 1783.23, "text": "And what we would determine\nis that to maximize"}, {"index": 535, "start": 1783.23, "dur": 3.56, "end": 1786.79, "text": "the probability of seeing this\ndata, this particular stuff"}, {"index": 536, "start": 1786.79, "dur": 3.35, "end": 1790.14, "text": "in a set of experiments, to\nmaximize that probability,"}, {"index": 537, "start": 1790.14, "dur": 5.72, "end": 1795.86, "text": "we would have to adjust T and\nw so as to get this curve doing"}, {"index": 538, "start": 1795.86, "dur": 1.91, "end": 1797.77, "text": "the optimal thing."}, {"index": 539, "start": 1797.77, "dur": 1.864, "end": 1799.634, "text": "And there&#39;s nothing\nmysterious about it."}, {"index": 540, "start": 1799.634, "dur": 1.416, "end": 1801.05, "text": "It&#39;s just more\npartial derivatives"}, {"index": 541, "start": 1801.05, "dur": 2.1, "end": 1803.15, "text": "and that sort of thing."}, {"index": 542, "start": 1803.15, "dur": 6.57, "end": 1809.72, "text": "But the bottom line is that the\nprobability of seeing this data"}, {"index": 543, "start": 1809.72, "dur": 2.85, "end": 1812.57, "text": "is dependent on the\nshape of this curve,"}, {"index": 544, "start": 1812.57, "dur": 3.97, "end": 1816.54, "text": "and the shape of this curve is\ndependent on those parameters."}, {"index": 545, "start": 1816.54, "dur": 2.79, "end": 1819.33, "text": "And if we wanted to maximize\nthe probability that we&#39;ve"}, {"index": 546, "start": 1819.33, "dur": 3.728, "end": 1823.058, "text": "seen this data, then we have\nto adjust those parameters"}, {"index": 547, "start": 1823.058, "dur": 0.5, "end": 1823.558, "text": "accordingly."}, {"index": 548, "start": 1823.558, "dur": 2.001, "end": 1825.559}, {"index": 549, "start": 1825.559, "dur": 1.541, "end": 1827.1, "text": "Let&#39;s have a look\nat a demonstration."}, {"index": 550, "start": 1827.1, "dur": 12.67, "end": 1839.77}, {"index": 551, "start": 1839.77, "dur": 0.5, "end": 1840.27, "text": "OK."}, {"index": 552, "start": 1840.27, "dur": 3.46, "end": 1843.73, "text": "So there&#39;s an ordinary\nsigmoid curve."}, {"index": 553, "start": 1843.73, "dur": 3.12, "end": 1846.85, "text": "Here are a couple of\npositive examples."}, {"index": 554, "start": 1846.85, "dur": 3.145, "end": 1849.995, "text": "Here&#39;s a negative example."}, {"index": 555, "start": 1849.995, "dur": 3.505, "end": 1853.5}, {"index": 556, "start": 1853.5, "dur": 4.67, "end": 1858.17, "text": "Let&#39;s put in some more\npositive examples over here."}, {"index": 557, "start": 1858.17, "dur": 6.5, "end": 1864.67, "text": "And now let&#39;s run the good,\nold gradient ascent algorithm"}, {"index": 558, "start": 1864.67, "dur": 2.2, "end": 1866.87, "text": "on that."}, {"index": 559, "start": 1866.87, "dur": 2.05, "end": 1868.92, "text": "And this is what happens."}, {"index": 560, "start": 1868.92, "dur": 2.72, "end": 1871.64, "text": "You&#39;ve seen how the\nprobability, as we adjust"}, {"index": 561, "start": 1871.64, "dur": 2.73, "end": 1874.37, "text": "the shape of the curve,\nthe probability of seeing"}, {"index": 562, "start": 1874.37, "dur": 3.69, "end": 1878.06, "text": "those examples of\nthe class goes up,"}, {"index": 563, "start": 1878.06, "dur": 4.89, "end": 1882.95, "text": "and the probability of seeing\nthe non-example goes down."}, {"index": 564, "start": 1882.95, "dur": 3.16, "end": 1886.11, "text": "So what if we put\nsome more examples in?"}, {"index": 565, "start": 1886.11, "dur": 1.53, "end": 1887.64, "text": "If we put a negative\nexample there,"}, {"index": 566, "start": 1887.64, "dur": 2.39, "end": 1890.03, "text": "not much is going to happen."}, {"index": 567, "start": 1890.03, "dur": 3.732, "end": 1893.762, "text": "What would happen if we put a\npositive example right there?"}, {"index": 568, "start": 1893.762, "dur": 2.208, "end": 1895.97, "text": "Then we&#39;re going to start\nseeing some dramatic shifts"}, {"index": 569, "start": 1895.97, "dur": 1.083, "end": 1897.053, "text": "in the shape of the curve."}, {"index": 570, "start": 1897.053, "dur": 10.947, "end": 1908}, {"index": 571, "start": 1908, "dur": 2.45, "end": 1910.45, "text": "So that&#39;s probably\na noise point."}, {"index": 572, "start": 1910.45, "dur": 4.3, "end": 1914.75, "text": "But we can put some more\nnegative examples in there"}, {"index": 573, "start": 1914.75, "dur": 1.512, "end": 1916.262, "text": "and see how that\nadjusts the curve."}, {"index": 574, "start": 1916.262, "dur": 3.248, "end": 1919.51}, {"index": 575, "start": 1919.51, "dur": 0.5, "end": 1920.01, "text": "All right."}, {"index": 576, "start": 1920.01, "dur": 1.125, "end": 1921.135, "text": "So that&#39;s what we&#39;re doing."}, {"index": 577, "start": 1921.135, "dur": 2.295, "end": 1923.43, "text": "We&#39;re viewing this\noutput value as something"}, {"index": 578, "start": 1923.43, "dur": 3.82, "end": 1927.25, "text": "that&#39;s related to the\nprobability of seeing a class."}, {"index": 579, "start": 1927.25, "dur": 2.65, "end": 1929.9, "text": "And we&#39;re adjusting the\nparameters on that output layer"}, {"index": 580, "start": 1929.9, "dur": 2.72, "end": 1932.62, "text": "so as to maximize the\nprobability of the sample data"}, {"index": 581, "start": 1932.62, "dur": 1.905, "end": 1934.525, "text": "that we&#39;ve got at hand."}, {"index": 582, "start": 1934.525, "dur": 0.5, "end": 1935.025, "text": "Right?"}, {"index": 583, "start": 1935.025, "dur": 2.905, "end": 1937.93}, {"index": 584, "start": 1937.93, "dur": 2.194, "end": 1940.124, "text": "Now, there&#39;s one more thing."}, {"index": 585, "start": 1940.124, "dur": 1.416, "end": 1941.54, "text": "Because see what\nwe&#39;ve got here is"}, {"index": 586, "start": 1941.54, "dur": 3.34, "end": 1944.88, "text": "we&#39;ve got the basic idea\nof back propagation, which"}, {"index": 587, "start": 1944.88, "dur": 5.32, "end": 1950.2, "text": "has layers and layers\nof additional--"}, {"index": 588, "start": 1950.2, "dur": 3.19, "end": 1953.39, "text": "let me be flattering and call\nthem ideas layered on top."}, {"index": 589, "start": 1953.39, "dur": 5.43, "end": 1958.82, "text": "So here&#39;s the next idea\nthat&#39;s layered on top."}, {"index": 590, "start": 1958.82, "dur": 4.29, "end": 1963.11, "text": "So we&#39;ve got an\noutput value here."}, {"index": 591, "start": 1963.11, "dur": 2.63, "end": 1965.74}, {"index": 592, "start": 1965.74, "dur": 4.53, "end": 1970.27, "text": "And it&#39;s a function after\nall, and it&#39;s got a value."}, {"index": 593, "start": 1970.27, "dur": 3.85, "end": 1974.12, "text": "And if we have\n1,000 classes, we&#39;re"}, {"index": 594, "start": 1974.12, "dur": 2.06, "end": 1976.18, "text": "going to have 1,000\noutput neurons,"}, {"index": 595, "start": 1976.18, "dur": 2.84, "end": 1979.02, "text": "and each is going to be\nproducing some kind of value."}, {"index": 596, "start": 1979.02, "dur": 3.306, "end": 1982.326, "text": "And we can think of that\nvalue as a probability."}, {"index": 597, "start": 1982.326, "dur": 2.379, "end": 1984.705}, {"index": 598, "start": 1984.705, "dur": 1.875, "end": 1986.58, "text": "But I didn&#39;t want to\nwrite a probability yet."}, {"index": 599, "start": 1986.58, "dur": 1.416, "end": 1987.996, "text": "I just want to say\nthat what we&#39;ve"}, {"index": 600, "start": 1987.996, "dur": 5.19, "end": 1993.186, "text": "got for this output neuron\nis a function of class 1."}, {"index": 601, "start": 1993.186, "dur": 1.874, "end": 1995.06, "text": "And then there will be\nanother output neuron,"}, {"index": 602, "start": 1995.06, "dur": 3.14, "end": 1998.2, "text": "which is a function of class 2."}, {"index": 603, "start": 1998.2, "dur": 2.84, "end": 2001.04, "text": "And these values will\nbe presumably higher--"}, {"index": 604, "start": 2001.04, "dur": 3.51, "end": 2004.55, "text": "this will be higher if we are,\nin fact, looking at class 1."}, {"index": 605, "start": 2004.55, "dur": 2.66, "end": 2007.21, "text": "And this one down here\nwill be, in fact, higher"}, {"index": 606, "start": 2007.21, "dur": 1.448, "end": 2008.658, "text": "if we&#39;re looking at class m."}, {"index": 607, "start": 2008.658, "dur": 3.162, "end": 2011.82}, {"index": 608, "start": 2011.82, "dur": 3.2, "end": 2015.02, "text": "So what we would like to do\nis we&#39;d like to not just pick"}, {"index": 609, "start": 2015.02, "dur": 2.93, "end": 2017.95, "text": "one of these outputs\nand say, well, you&#39;ve"}, {"index": 610, "start": 2017.95, "dur": 2.6, "end": 2020.55, "text": "got the highest\nvalue, so you win."}, {"index": 611, "start": 2020.55, "dur": 2.16, "end": 2022.71, "text": "What we want to do\ninstead is we want"}, {"index": 612, "start": 2022.71, "dur": 2.42, "end": 2025.13, "text": "to associate some\nkind of probability"}, {"index": 613, "start": 2025.13, "dur": 1.944, "end": 2027.074, "text": "with each of the classes."}, {"index": 614, "start": 2027.074, "dur": 1.666, "end": 2028.74, "text": "Because, after all,\nwe want to do things"}, {"index": 615, "start": 2028.74, "dur": 3.862, "end": 2032.602, "text": "like find the most\nprobable five."}, {"index": 616, "start": 2032.602, "dur": 1.458, "end": 2034.06, "text": "So what we do is\nwe say, all right,"}, {"index": 617, "start": 2034.06, "dur": 5.89, "end": 2039.95, "text": "so the actual\nprobability of class 1"}, {"index": 618, "start": 2039.95, "dur": 8.04, "end": 2047.99, "text": "is equal to the output of\nthat sigmoid function divided"}, {"index": 619, "start": 2047.99, "dur": 3.367, "end": 2051.357, "text": "by the sum over all functions."}, {"index": 620, "start": 2051.357, "dur": 3.552, "end": 2054.909}, {"index": 621, "start": 2054.909, "dur": 2.33, "end": 2057.239, "text": "So that takes all of\nthat entire output vector"}, {"index": 622, "start": 2057.239, "dur": 3.681, "end": 2060.92, "text": "and converts each output\nvalue into a probability."}, {"index": 623, "start": 2060.92, "dur": 3.555, "end": 2064.475, "text": "So when we used that\nsigmoid function,"}, {"index": 624, "start": 2064.475, "dur": 1.625, "end": 2066.1, "text": "we did it with the\nview toward thinking"}, {"index": 625, "start": 2066.1, "dur": 1.166, "end": 2067.266, "text": "about that as a probability."}, {"index": 626, "start": 2067.266, "dur": 2.734, "end": 2070, "text": "And in fact, we assumed\nit was a probability when"}, {"index": 627, "start": 2070, "dur": 2.429, "end": 2072.429, "text": "we made this argument."}, {"index": 628, "start": 2072.429, "dur": 2.741, "end": 2075.17, "text": "But in the end,\nthere&#39;s an output"}, {"index": 629, "start": 2075.17, "dur": 1.11, "end": 2076.28, "text": "for each of those classes."}, {"index": 630, "start": 2076.28, "dur": 2.72, "end": 2079.0000000000005, "text": "And so what we get is, in the\nend, not exactly a probability"}, {"index": 631, "start": 2079, "dur": 4.219, "end": 2083.219, "text": "until we divide by a\nnormalizing factor."}, {"index": 632, "start": 2083.219, "dur": 6.281, "end": 2089.5, "text": "So this, by the way, is called--\nnot on my list of things,"}, {"index": 633, "start": 2089.5, "dur": 1.026, "end": 2090.526, "text": "but it soon will be."}, {"index": 634, "start": 2090.526, "dur": 4.054, "end": 2094.58}, {"index": 635, "start": 2094.58, "dur": 5.06, "end": 2099.64, "text": "Since we&#39;re not talking\nabout taking the maximum"}, {"index": 636, "start": 2099.64, "dur": 2.94, "end": 2102.58, "text": "and using that to classify the\npicture, what we&#39;re going to do"}, {"index": 637, "start": 2102.58, "dur": 2.71, "end": 2105.29, "text": "is we&#39;re going to use\nwhat&#39;s called softmax."}, {"index": 638, "start": 2105.29, "dur": 3.85, "end": 2109.14}, {"index": 639, "start": 2109.14, "dur": 2.59, "end": 2111.73, "text": "So we&#39;re going to give a\nrange of classifications,"}, {"index": 640, "start": 2111.73, "dur": 2.95, "end": 2114.68, "text": "and we&#39;re going to associate\na probability with each."}, {"index": 641, "start": 2114.68, "dur": 3.93, "end": 2118.61, "text": "And that&#39;s what you saw\nin all of those samples."}, {"index": 642, "start": 2118.61, "dur": 1.75, "end": 2120.36, "text": "You saw, yes, this is\n[? containership, ?]"}, {"index": 643, "start": 2120.36, "dur": 3.71, "end": 2124.07, "text": "but maybe it&#39;s also this,\nthat, or a third, or fourth,"}, {"index": 644, "start": 2124.07, "dur": 2.69, "end": 2126.76, "text": "and fifth thing."}, {"index": 645, "start": 2126.76, "dur": 5.164, "end": 2131.924, "text": "So that is a pretty good\nsummary of the kinds"}, {"index": 646, "start": 2131.924, "dur": 1.166, "end": 2133.09, "text": "of things that are involved."}, {"index": 647, "start": 2133.09, "dur": 3.8, "end": 2136.89, "text": "But now we&#39;ve got one more\nstep, because what we can do now"}, {"index": 648, "start": 2136.89, "dur": 4.2, "end": 2141.09, "text": "is we can take this output\nlayer idea, this softmax idea,"}, {"index": 649, "start": 2141.09, "dur": 2.38, "end": 2143.47, "text": "and we can put them together\nwith the autocoding idea."}, {"index": 650, "start": 2143.47, "dur": 4.3, "end": 2147.77}, {"index": 651, "start": 2147.77, "dur": 3.05, "end": 2150.82, "text": "So we&#39;ve trained\njust a layer up."}, {"index": 652, "start": 2150.82, "dur": 2.88, "end": 2153.7, "text": "And now we&#39;re going to detach\nit from the output layer"}, {"index": 653, "start": 2153.7, "dur": 2.1, "end": 2155.8, "text": "but retain those\nweights that connect"}, {"index": 654, "start": 2155.8, "dur": 2.37, "end": 2158.17, "text": "the input to the hidden layer."}, {"index": 655, "start": 2158.17, "dur": 2.39, "end": 2160.56, "text": "And when we do that,\nwhat we&#39;re going to see"}, {"index": 656, "start": 2160.56, "dur": 2.87, "end": 2163.43, "text": "is something that\nlooks like this."}, {"index": 657, "start": 2163.43, "dur": 1.98, "end": 2165.41, "text": "And now we&#39;ve got a\ntrained first layer"}, {"index": 658, "start": 2165.41, "dur": 2.44, "end": 2167.85, "text": "but an untrained output layer."}, {"index": 659, "start": 2167.85, "dur": 2.43, "end": 2170.28, "text": "We&#39;re going to freeze\nthe input layer"}, {"index": 660, "start": 2170.28, "dur": 6.31, "end": 2176.59, "text": "and train the output layer\nusing the sigmoid curve"}, {"index": 661, "start": 2176.59, "dur": 1.55, "end": 2178.14, "text": "and see what happens\nwhen we do that."}, {"index": 662, "start": 2178.14, "dur": 3.585, "end": 2181.725, "text": "Oh, by the way, let&#39;s run\nour test samples through."}, {"index": 663, "start": 2181.725, "dur": 1.5, "end": 2183.225, "text": "You can see it&#39;s\nnot doing anything,"}, {"index": 664, "start": 2183.225, "dur": 3.955, "end": 2187.18, "text": "and the output is half\nfor each of the categories"}, {"index": 665, "start": 2187.18, "dur": 2.21, "end": 2189.39, "text": "even though we&#39;ve got\na trained middle layer."}, {"index": 666, "start": 2189.39, "dur": 1.5, "end": 2190.89, "text": "So we have to train\nthe outer layer."}, {"index": 667, "start": 2190.89, "dur": 1.936, "end": 2192.826, "text": "Let&#39;s see how long it takes."}, {"index": 668, "start": 2192.826, "dur": 1.124, "end": 2193.95, "text": "Whoa, that was pretty fast."}, {"index": 669, "start": 2193.95, "dur": 2.93, "end": 2196.88}, {"index": 670, "start": 2196.88, "dur": 3.33, "end": 2200.21, "text": "Now there&#39;s an extraordinarily\ngood match between the outputs"}, {"index": 671, "start": 2200.21, "dur": 1.599, "end": 2201.809, "text": "and the desired outputs."}, {"index": 672, "start": 2201.809, "dur": 1.791, "end": 2203.6, "text": "So that&#39;s the combination\nof the autocoding"}, {"index": 673, "start": 2203.6, "dur": 1.941, "end": 2205.541, "text": "idea and the softmax idea."}, {"index": 674, "start": 2205.541, "dur": 4.609, "end": 2210.15}, {"index": 675, "start": 2210.15, "dur": 5.39, "end": 2215.54, "text": "[? There&#39;s ?] just one more\nidea that&#39;s worthy of mention,"}, {"index": 676, "start": 2215.54, "dur": 1.48, "end": 2217.02, "text": "and that&#39;s the idea of dropout."}, {"index": 677, "start": 2217.02, "dur": 3.3, "end": 2220.32}, {"index": 678, "start": 2220.32, "dur": 2.56, "end": 2222.88, "text": "The plague of any neural\nnet is that it gets stuck"}, {"index": 679, "start": 2222.88, "dur": 3.16, "end": 2226.04, "text": "in some kind of local maximum."}, {"index": 680, "start": 2226.04, "dur": 2.7, "end": 2228.74, "text": "So it was discovered\nthat these things train"}, {"index": 681, "start": 2228.74, "dur": 7.76, "end": 2236.5, "text": "better if, on every\niteration, you"}, {"index": 682, "start": 2236.5, "dur": 3.12, "end": 2239.62, "text": "flip a coin for each neuron."}, {"index": 683, "start": 2239.62, "dur": 2.64, "end": 2242.26, "text": "And if the coin\nends up tails, you"}, {"index": 684, "start": 2242.26, "dur": 4.66, "end": 2246.92, "text": "assume it&#39;s just died and has\nno influence on the output."}, {"index": 685, "start": 2246.92, "dur": 3.01, "end": 2249.93, "text": "It&#39;s called dropping\nout those neurons."}, {"index": 686, "start": 2249.93, "dur": 4.02, "end": 2253.95, "text": "And in our next iteration,\nyou drop out a different set."}, {"index": 687, "start": 2253.95, "dur": 1.71, "end": 2255.66, "text": "So what this seems\nto do is it seems"}, {"index": 688, "start": 2255.66, "dur": 5.361, "end": 2261.021, "text": "to prevent this thing from going\ninto a frozen local maximum"}, {"index": 689, "start": 2261.021, "dur": 0.499, "end": 2261.52, "text": "state."}, {"index": 690, "start": 2261.52, "dur": 3.32, "end": 2264.84}, {"index": 691, "start": 2264.84, "dur": 1.39, "end": 2266.23, "text": "So that&#39;s deep nets."}, {"index": 692, "start": 2266.23, "dur": 3.77, "end": 2270, "text": "They should be called, by the\nway, wide nets because they"}, {"index": 693, "start": 2270, "dur": 3.02, "end": 2273.02, "text": "tend to be enormously\nwide but rarely"}, {"index": 694, "start": 2273.02, "dur": 8.23, "end": 2281.25, "text": "more than 10 columns deep."}, {"index": 695, "start": 2281.25, "dur": 2.8, "end": 2284.05, "text": "Now, let&#39;s see, where\nto go from here?"}, {"index": 696, "start": 2284.05, "dur": 6.85, "end": 2290.9, "text": "Maybe what we should do is talk\nabout the awesome curiosity"}, {"index": 697, "start": 2290.9, "dur": 2.92, "end": 2293.82, "text": "in the current state of the art."}, {"index": 698, "start": 2293.82, "dur": 4.09, "end": 2297.91, "text": "And that is that\nall of [? this ?]"}, {"index": 699, "start": 2297.91, "dur": 3.84, "end": 2301.75, "text": "sophistication with output\nlayers that are probabilities"}, {"index": 700, "start": 2301.75, "dur": 6.83, "end": 2308.58, "text": "and training using autocoding\nor Boltzmann machines,"}, {"index": 701, "start": 2308.58, "dur": 4.61, "end": 2313.19, "text": "it doesn&#39;t seem to help much\nrelative to plain, old back"}, {"index": 702, "start": 2313.19, "dur": 2.45, "end": 2315.64, "text": "propagation."}, {"index": 703, "start": 2315.64, "dur": 2.45, "end": 2318.09, "text": "So back propagation\nwith a convolutional net"}, {"index": 704, "start": 2318.09, "dur": 3.54, "end": 2321.63, "text": "seems to do just about\nas good as anything."}, {"index": 705, "start": 2321.63, "dur": 4.9, "end": 2326.53, "text": "And while we&#39;re on the subject\nof an ordinary deep net,"}, {"index": 706, "start": 2326.53, "dur": 3.54, "end": 2330.07, "text": "I&#39;d like to examine\na situation here"}, {"index": 707, "start": 2330.07, "dur": 9.105, "end": 2339.175, "text": "where we have a deep net--\nwell, it&#39;s a classroom deep net."}, {"index": 708, "start": 2339.175, "dur": 3.495, "end": 2342.67, "text": "And we&#39;ll will put\nfive layers in there,"}, {"index": 709, "start": 2342.67, "dur": 2.26, "end": 2344.93, "text": "and its job is still\nto do the same thing."}, {"index": 710, "start": 2344.93, "dur": 4.7, "end": 2349.63, "text": "It&#39;s to classify an animal as a\ncheetah, a zebra, or a giraffe"}, {"index": 711, "start": 2349.63, "dur": 4, "end": 2353.63, "text": "based on the height of\nthe shadow it casts."}, {"index": 712, "start": 2353.63, "dur": 2.98, "end": 2356.61, "text": "And as before, if it&#39;s\ngreen, that means positive."}, {"index": 713, "start": 2356.61, "dur": 2.69, "end": 2359.3, "text": "If it&#39;s red, that\nmeans negative."}, {"index": 714, "start": 2359.3, "dur": 3.36, "end": 2362.66, "text": "And right at the moment,\nwe have no training."}, {"index": 715, "start": 2362.66, "dur": 1.76, "end": 2364.42, "text": "So if we run our\ntest samples through,"}, {"index": 716, "start": 2364.42, "dur": 4.7, "end": 2369.12, "text": "the output is always a 1/2\nno matter what the animal is."}, {"index": 717, "start": 2369.12, "dur": 0.855, "end": 2369.975, "text": "All right?"}, {"index": 718, "start": 2369.975, "dur": 1.375, "end": 2371.35, "text": "So what we&#39;re\ngoing to do is just"}, {"index": 719, "start": 2371.35, "dur": 3.57, "end": 2374.92, "text": "going to use ordinary back\nprop on this, same thing"}, {"index": 720, "start": 2374.92, "dur": 7.05, "end": 2381.97, "text": "as in that sample that&#39;s\nunderneath the blackboard."}, {"index": 721, "start": 2381.97, "dur": 1.92, "end": 2383.89, "text": "Only now we&#39;ve got a\nlot more parameters."}, {"index": 722, "start": 2383.89, "dur": 3.06, "end": 2386.95, "text": "We&#39;ve got five columns,\nand each one of them"}, {"index": 723, "start": 2386.95, "dur": 3.37, "end": 2390.32, "text": "has 9 or 10 neurons in it."}, {"index": 724, "start": 2390.32, "dur": 1.95, "end": 2392.27, "text": "So let&#39;s let this one run."}, {"index": 725, "start": 2392.27, "dur": 3.89, "end": 2396.16}, {"index": 726, "start": 2396.16, "dur": 1.58, "end": 2397.74, "text": "Now, look at that\nstuff on the right."}, {"index": 727, "start": 2397.74, "dur": 1.57, "end": 2399.31, "text": "It&#39;s all turned red."}, {"index": 728, "start": 2399.31, "dur": 3.96, "end": 2403.27, "text": "At first I thought this\nwas a bug in my program."}, {"index": 729, "start": 2403.27, "dur": 1.429, "end": 2404.699, "text": "But that makes absolute sense."}, {"index": 730, "start": 2404.699, "dur": 2.291, "end": 2406.99, "text": "If you don&#39;t know what the\nactual animal is going to be"}, {"index": 731, "start": 2406.99, "dur": 1.875, "end": 2408.865, "text": "and there are a whole\nbunch of possibilities,"}, {"index": 732, "start": 2408.865, "dur": 2.105, "end": 2410.97, "text": "you better just say\nno for everybody."}, {"index": 733, "start": 2410.97, "dur": 2.58, "end": 2413.55, "text": "It&#39;s like when a biologist\nsays, we don&#39;t know."}, {"index": 734, "start": 2413.55, "dur": 2.83, "end": 2416.38, "text": "It&#39;s the most probable answer."}, {"index": 735, "start": 2416.38, "dur": 4.02, "end": 2420.4, "text": "Well, but eventually, after\nabout 160,000 iterations,"}, {"index": 736, "start": 2420.4, "dur": 1, "end": 2421.4, "text": "it seems to have got it."}, {"index": 737, "start": 2421.4, "dur": 1.458, "end": 2422.858, "text": "Let&#39;s run the test\nsamples through."}, {"index": 738, "start": 2422.858, "dur": 4.186, "end": 2427.044}, {"index": 739, "start": 2427.044, "dur": 2.266, "end": 2429.31, "text": "Now it&#39;s doing great."}, {"index": 740, "start": 2429.31, "dur": 2.077, "end": 2431.387, "text": "Let&#39;s do it again just to\nsee if this is a fluke."}, {"index": 741, "start": 2431.387, "dur": 5.744, "end": 2437.131}, {"index": 742, "start": 2437.131, "dur": 15.459, "end": 2452.59, "text": "And all red on the right\nside, and finally, you"}, {"index": 743, "start": 2452.59, "dur": 4.34, "end": 2456.93, "text": "start seeing some changes go\nin the final layers there."}, {"index": 744, "start": 2456.93, "dur": 2.67, "end": 2459.6, "text": "And if you look at the error\nrate down at the bottom,"}, {"index": 745, "start": 2459.6, "dur": 3.1, "end": 2462.7, "text": "you&#39;ll see that it kind\nof falls off a cliff."}, {"index": 746, "start": 2462.7, "dur": 2.106, "end": 2464.806, "text": "So nothing happens\nfor a real long time,"}, {"index": 747, "start": 2464.806, "dur": 1.25, "end": 2466.056, "text": "and then it falls off a cliff."}, {"index": 748, "start": 2466.056, "dur": 3.504, "end": 2469.56}, {"index": 749, "start": 2469.56, "dur": 4.06, "end": 2473.62, "text": "Now, what would happen if\nthis neural net were not"}, {"index": 750, "start": 2473.62, "dur": 2.24, "end": 2475.86, "text": "quite so wide?"}, {"index": 751, "start": 2475.86, "dur": 0.9, "end": 2476.76, "text": "Good question."}, {"index": 752, "start": 2476.76, "dur": 2.333, "end": 2479.093, "text": "But before we get to that\nquestion, what I&#39;m going to do"}, {"index": 753, "start": 2479.093, "dur": 2.787, "end": 2481.88, "text": "is I&#39;m going to do a\nfunny kind of variation"}, {"index": 754, "start": 2481.88, "dur": 1.796, "end": 2483.676, "text": "on the theme of dropout."}, {"index": 755, "start": 2483.676, "dur": 1.374, "end": 2485.05, "text": "What I&#39;m going to\ndo is I&#39;m going"}, {"index": 756, "start": 2485.05, "dur": 3.02, "end": 2488.07, "text": "to kill off one\nneuron in each column,"}, {"index": 757, "start": 2488.07, "dur": 2.52, "end": 2490.59, "text": "and then see if I can\nretrain the network"}, {"index": 758, "start": 2490.59, "dur": 3.16, "end": 2493.75, "text": "to do the right thing."}, {"index": 759, "start": 2493.75, "dur": 3.46, "end": 2497.21, "text": "So I&#39;m going to reassign\nthose to some other purpose."}, {"index": 760, "start": 2497.21, "dur": 2.89, "end": 2500.1, "text": "So now there&#39;s one fewer\nneuron in the network."}, {"index": 761, "start": 2500.1, "dur": 4.522, "end": 2504.622, "text": "If we rerun that, we see that\nit trains itself up very fast."}, {"index": 762, "start": 2504.622, "dur": 1.458, "end": 2506.08, "text": "So we seem to be\nstill close enough"}, {"index": 763, "start": 2506.08, "dur": 4.39, "end": 2510.47, "text": "to a solution we\ncan do without one"}, {"index": 764, "start": 2510.47, "dur": 1.64, "end": 2512.11, "text": "of the neurons in each column."}, {"index": 765, "start": 2512.11, "dur": 0.81, "end": 2512.92, "text": "Let&#39;s do it again."}, {"index": 766, "start": 2512.92, "dur": 2.349, "end": 2515.269}, {"index": 767, "start": 2515.269, "dur": 1.791, "end": 2517.06, "text": "Now it goes up a little\nbit, but it quickly"}, {"index": 768, "start": 2517.06, "dur": 2.47, "end": 2519.53, "text": "falls down to a solution."}, {"index": 769, "start": 2519.53, "dur": 2.53, "end": 2522.06, "text": "Try again."}, {"index": 770, "start": 2522.06, "dur": 3.56, "end": 2525.62, "text": "Quickly falls down\nto a solution."}, {"index": 771, "start": 2525.62, "dur": 2.94, "end": 2528.56, "text": "Oh, my god, how much of\nthis am I going to do?"}, {"index": 772, "start": 2528.56, "dur": 2.41, "end": 2530.97, "text": "Each time I knock\nsomething out and retrain,"}, {"index": 773, "start": 2530.97, "dur": 2.04, "end": 2533.01, "text": "it finds its solution very fast."}, {"index": 774, "start": 2533.01, "dur": 17.47, "end": 2550.48}, {"index": 775, "start": 2550.48, "dur": 3.69, "end": 2554.17, "text": "Whoa, I got it all the way down\nto two neurons in each column,"}, {"index": 776, "start": 2554.17, "dur": 3.12, "end": 2557.29, "text": "and it still has a solution."}, {"index": 777, "start": 2557.29, "dur": 3.15, "end": 2560.44, "text": "It&#39;s interesting,\ndon&#39;t you think?"}, {"index": 778, "start": 2560.44, "dur": 2.68, "end": 2563.12, "text": "But let&#39;s repeat the\nexperiment, but this time we&#39;re"}, {"index": 779, "start": 2563.12, "dur": 2.061, "end": 2565.181, "text": "going to do it a\nlittle differently."}, {"index": 780, "start": 2565.181, "dur": 1.534, "end": 2566.715, "text": "We&#39;re going to take\nour five layers,"}, {"index": 781, "start": 2566.715, "dur": 2.895, "end": 2569.61, "text": "and before we do\nany training I&#39;m"}, {"index": 782, "start": 2569.61, "dur": 7.78, "end": 2577.39, "text": "going to knock out all but\ntwo neurons in each column."}, {"index": 783, "start": 2577.39, "dur": 2.37, "end": 2579.76, "text": "Now, I know that with two\nneurons in each column,"}, {"index": 784, "start": 2579.76, "dur": 1.76, "end": 2581.52, "text": "I&#39;ve got a solution."}, {"index": 785, "start": 2581.52, "dur": 0.85, "end": 2582.37, "text": "I just showed it."}, {"index": 786, "start": 2582.37, "dur": 0.975, "end": 2583.345, "text": "I just showed one."}, {"index": 787, "start": 2583.345, "dur": 2.705, "end": 2586.05, "text": "But let&#39;s run it this way."}, {"index": 788, "start": 2586.05, "dur": 13.01, "end": 2599.06}, {"index": 789, "start": 2599.06, "dur": 4.73, "end": 2603.79, "text": "It looks like\nincreasingly bad news."}, {"index": 790, "start": 2603.79, "dur": 2.02, "end": 2605.81, "text": "What&#39;s happened is that\nthis sucker&#39;s got itself"}, {"index": 791, "start": 2605.81, "dur": 2.63, "end": 2608.44, "text": "into a local maximum."}, {"index": 792, "start": 2608.44, "dur": 3.11, "end": 2611.55, "text": "So now you can see\nwhy there&#39;s been"}, {"index": 793, "start": 2611.55, "dur": 4.05, "end": 2615.6, "text": "a breakthrough in this\nneural net learning stuff."}, {"index": 794, "start": 2615.6, "dur": 3.7, "end": 2619.3, "text": "And it&#39;s because when\nyou widen the net,"}, {"index": 795, "start": 2619.3, "dur": 4.45, "end": 2623.75, "text": "you turn local maxima\ninto saddle points."}, {"index": 796, "start": 2623.75, "dur": 1.81, "end": 2625.56, "text": "So now it&#39;s got a way\nof crawling its way"}, {"index": 797, "start": 2625.56, "dur": 3.23, "end": 2628.79, "text": "through this vast\nspace without getting"}, {"index": 798, "start": 2628.79, "dur": 4.86, "end": 2633.65, "text": "stuck on a local maximum,\nas suggested by this."}, {"index": 799, "start": 2633.65, "dur": 0.5, "end": 2634.15, "text": "All right."}, {"index": 800, "start": 2634.15, "dur": 3.73, "end": 2637.88, "text": "So those are some, I\nthink, interesting things"}, {"index": 801, "start": 2637.88, "dur": 3.93, "end": 2641.81, "text": "to look at by way of\nthese demonstrations."}, {"index": 802, "start": 2641.81, "dur": 2.7, "end": 2644.51, "text": "But now I&#39;d like to go\nback to my slide set"}, {"index": 803, "start": 2644.51, "dur": 2.35, "end": 2646.86, "text": "and show you some\nexamples that will address"}, {"index": 804, "start": 2646.86, "dur": 2.81, "end": 2649.67, "text": "the question of whether these\nthings are seeing like we see."}, {"index": 805, "start": 2649.67, "dur": 10.94, "end": 2660.61}, {"index": 806, "start": 2660.61, "dur": 1.77, "end": 2662.38, "text": "So you can try these\nexamples online."}, {"index": 807, "start": 2662.38, "dur": 1.99, "end": 2664.37, "text": "There are a variety\nof websites that allow"}, {"index": 808, "start": 2664.37, "dur": 3.58, "end": 2667.95, "text": "you to put in your own picture."}, {"index": 809, "start": 2667.95, "dur": 5.56, "end": 2673.51, "text": "And there&#39;s a cottage industry\nof producing papers in journals"}, {"index": 810, "start": 2673.51, "dur": 2.33, "end": 2675.84, "text": "that fool neural nets."}, {"index": 811, "start": 2675.84, "dur": 2.76, "end": 2678.6, "text": "So in this case, a very\nsmall number of pixels"}, {"index": 812, "start": 2678.6, "dur": 0.82, "end": 2679.42, "text": "have been changed."}, {"index": 813, "start": 2679.42, "dur": 2.22, "end": 2681.64, "text": "You don&#39;t see the\ndifference, but it&#39;s"}, {"index": 814, "start": 2681.64, "dur": 2.65, "end": 2684.29, "text": "enough to take this\nparticular neural net"}, {"index": 815, "start": 2684.29, "dur": 3.56, "end": 2687.85, "text": "from a high confidence that\nit&#39;s looking at a school bus"}, {"index": 816, "start": 2687.85, "dur": 3.927, "end": 2691.777, "text": "to thinking that it&#39;s\nnot a school bus."}, {"index": 817, "start": 2691.777, "dur": 2.249, "end": 2694.026, "text": "Those are some things that\nit thinks are a school bus."}, {"index": 818, "start": 2694.026, "dur": 2.754, "end": 2696.78}, {"index": 819, "start": 2696.78, "dur": 1.71, "end": 2698.49, "text": "So it appears to be\nthe case that what"}, {"index": 820, "start": 2698.49, "dur": 2.83, "end": 2701.32, "text": "is triggering this\nschool bus result"}, {"index": 821, "start": 2701.32, "dur": 3.02, "end": 2704.34, "text": "is that it&#39;s seeing enough\nlocal evidence that this is not"}, {"index": 822, "start": 2704.34, "dur": 5.74, "end": 2710.08, "text": "one of the other 999 classes\nand enough positive evidence"}, {"index": 823, "start": 2710.08, "dur": 2.23, "end": 2712.31, "text": "from these local\nlooks to conclude"}, {"index": 824, "start": 2712.31, "dur": 1.003, "end": 2713.313, "text": "that it&#39;s a school bus."}, {"index": 825, "start": 2713.313, "dur": 4.707, "end": 2718.02}, {"index": 826, "start": 2718.02, "dur": 2.31, "end": 2720.33, "text": "So do you see any\nof those things?"}, {"index": 827, "start": 2720.33, "dur": 0.54, "end": 2720.87, "text": "I don&#39;t."}, {"index": 828, "start": 2720.87, "dur": 3.624, "end": 2724.494}, {"index": 829, "start": 2724.494, "dur": 3.796, "end": 2728.29, "text": "And here you can say, OK, well,\nlook at that baseball one."}, {"index": 830, "start": 2728.29, "dur": 3.21, "end": 2731.5, "text": "Yeah, that looks like it&#39;s got\na little bit of baseball texture"}, {"index": 831, "start": 2731.5, "dur": 0.52, "end": 2732.02, "text": "in it."}, {"index": 832, "start": 2732.02, "dur": 1.958, "end": 2733.978, "text": "So maybe what it&#39;s doing\nis looking at texture."}, {"index": 833, "start": 2733.978, "dur": 5.152, "end": 2739.13}, {"index": 834, "start": 2739.13, "dur": 4.25, "end": 2743.38, "text": "These are some examples from\na recent and very famous"}, {"index": 835, "start": 2743.38, "dur": 4, "end": 2747.38, "text": "paper by Google using\nessentially the same ideas"}, {"index": 836, "start": 2747.38, "dur": 3.91, "end": 2751.29, "text": "to put captions on pictures."}, {"index": 837, "start": 2751.29, "dur": 2.5, "end": 2753.79, "text": "So this, by the way,\nis what has stimulated"}, {"index": 838, "start": 2753.79, "dur": 2.83, "end": 2756.62, "text": "all this enormous concern\nabout artificial intelligence."}, {"index": 839, "start": 2756.62, "dur": 2.25, "end": 2758.87, "text": "Because a naive viewer looks\nat that picture and says,"}, {"index": 840, "start": 2758.87, "dur": 1.375, "end": 2760.245, "text": "oh, my god, this\nthing knows what"}, {"index": 841, "start": 2760.245, "dur": 6.015, "end": 2766.26, "text": "it&#39;s like to play, or be young,\nor move, or what a Frisbee is."}, {"index": 842, "start": 2766.26, "dur": 1.81, "end": 2768.07, "text": "And of course, it\nknows none of that."}, {"index": 843, "start": 2768.07, "dur": 2.88, "end": 2770.95, "text": "It just knows how to\nlabel this picture."}, {"index": 844, "start": 2770.95, "dur": 3.13, "end": 2774.08, "text": "And to the credit of the\npeople who wrote this paper,"}, {"index": 845, "start": 2774.08, "dur": 3.46, "end": 2777.54, "text": "they show examples\nthat don&#39;t do so well."}, {"index": 846, "start": 2777.54, "dur": 3.46, "end": 2781, "text": "So yeah, it&#39;s a cat,\nbut it&#39;s not lying."}, {"index": 847, "start": 2781, "dur": 3.62, "end": 2784.62, "text": "Oh, it&#39;s a little girl, but\nshe&#39;s not blowing bubbles."}, {"index": 848, "start": 2784.62, "dur": 1.264, "end": 2785.884, "text": "What about this one?"}, {"index": 849, "start": 2785.884, "dur": 2.964, "end": 2788.848, "text": "[LAUGHTER]"}, {"index": 850, "start": 2788.848, "dur": 2.972, "end": 2791.82}, {"index": 851, "start": 2791.82, "dur": 2.95, "end": 2794.77, "text": "So we&#39;ve been doing our\nown work in my laboratory"}, {"index": 852, "start": 2794.77, "dur": 1.62, "end": 2796.39, "text": "on some of this."}, {"index": 853, "start": 2796.39, "dur": 3.51, "end": 2799.9, "text": "And the way the following set of\npictures was produced was this."}, {"index": 854, "start": 2799.9, "dur": 2.01, "end": 2801.91, "text": "You take an image,\nand you separate it"}, {"index": 855, "start": 2801.91, "dur": 2.4, "end": 2804.31, "text": "into a bunch of slices,\neach representing"}, {"index": 856, "start": 2804.31, "dur": 2.45, "end": 2806.76, "text": "a particular frequency band."}, {"index": 857, "start": 2806.76, "dur": 2.54, "end": 2809.3, "text": "And then you go into one\nof those frequency bands"}, {"index": 858, "start": 2809.3, "dur": 2.38, "end": 2811.68, "text": "and you knock out a\nrectangle from the picture,"}, {"index": 859, "start": 2811.68, "dur": 3.05, "end": 2814.73, "text": "and then you\nreassemble the thing."}, {"index": 860, "start": 2814.73, "dur": 2.146, "end": 2816.876, "text": "And if you hadn&#39;t\nknocked that piece out,"}, {"index": 861, "start": 2816.876, "dur": 1.874, "end": 2818.75, "text": "when you reassemble it,\nit would look exactly"}, {"index": 862, "start": 2818.75, "dur": 2.01, "end": 2820.76, "text": "like it did when you started."}, {"index": 863, "start": 2820.76, "dur": 2.61, "end": 2823.37, "text": "So what we&#39;re doing is we\nknock out as much as we can"}, {"index": 864, "start": 2823.37, "dur": 2.457, "end": 2825.827, "text": "and still retain the\nneural net&#39;s impression"}, {"index": 865, "start": 2825.827, "dur": 2.333, "end": 2828.16, "text": "that it&#39;s the thing that it\nstarted out thinking it was."}, {"index": 866, "start": 2828.16, "dur": 1.415, "end": 2829.575, "text": "So what do you think this is?"}, {"index": 867, "start": 2829.575, "dur": 4.065, "end": 2833.64}, {"index": 868, "start": 2833.64, "dur": 3.67, "end": 2837.31, "text": "It&#39;s identified by a neural\nnet as a railroad car"}, {"index": 869, "start": 2837.31, "dur": 4.279, "end": 2841.589, "text": "because this is the image\nthat it started with."}, {"index": 870, "start": 2841.589, "dur": 0.791, "end": 2842.38, "text": "How about this one?"}, {"index": 871, "start": 2842.38, "dur": 0.99, "end": 2843.37, "text": "That&#39;s easy, right?"}, {"index": 872, "start": 2843.37, "dur": 1.73, "end": 2845.1, "text": "That&#39;s a guitar."}, {"index": 873, "start": 2845.1, "dur": 2.99, "end": 2848.09, "text": "We weren&#39;t able to mutilate that\none very much and still retain"}, {"index": 874, "start": 2848.09, "dur": 2.74, "end": 2850.83, "text": "the guitar-ness of it."}, {"index": 875, "start": 2850.83, "dur": 1.49, "end": 2852.32, "text": "How about this one?"}, {"index": 876, "start": 2852.32, "dur": 0.709, "end": 2853.029, "text": "AUDIENCE: A lamp?"}, {"index": 877, "start": 2853.029, "dur": 1.332, "end": 2854.361, "text": "PATRICK H. WINSTON: What&#39;s that?"}, {"index": 878, "start": 2854.361, "dur": 0.659, "end": 2855.02, "text": "AUDIENCE: Lamp."}, {"index": 879, "start": 2855.02, "dur": 0.23, "end": 2855.25, "text": "PATRICK H. WINSTON: What?"}, {"index": 880, "start": 2855.25, "dur": 0.94, "end": 2856.19, "text": "AUDIENCE: Lamp."}, {"index": 881, "start": 2856.19, "dur": 1.14, "end": 2857.33, "text": "PATRICK H. WINSTON: A lamp."}, {"index": 882, "start": 2857.33, "dur": 0.737, "end": 2858.067, "text": "Any other ideas?"}, {"index": 883, "start": 2858.067, "dur": 0.916, "end": 2858.983, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 884, "start": 2858.983, "dur": 1.297, "end": 2860.28, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 885, "start": 2860.28, "dur": 2.041, "end": 2862.321, "text": "PATRICK H. WINSTON: Ken,\nwhat do you think it is?"}, {"index": 886, "start": 2862.321, "dur": 0.836, "end": 2863.157, "text": "AUDIENCE: A toilet."}, {"index": 887, "start": 2863.157, "dur": 2.333, "end": 2865.49, "text": "PATRICK H. WINSTON: See, he&#39;s\nan expert on this subject."}, {"index": 888, "start": 2865.49, "dur": 1.39, "end": 2866.88, "text": "[LAUGHTER]"}, {"index": 889, "start": 2866.88, "dur": 3.6, "end": 2870.48, "text": "It was identified as a barbell."}, {"index": 890, "start": 2870.48, "dur": 0.81, "end": 2871.29, "text": "What&#39;s that?"}, {"index": 891, "start": 2871.29, "dur": 0.916, "end": 2872.206, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 892, "start": 2872.206, "dur": 1.244, "end": 2873.45, "text": "PATRICK H. WINSTON: A what?"}, {"index": 893, "start": 2873.45, "dur": 0.89, "end": 2874.34, "text": "AUDIENCE: Cello."}, {"index": 894, "start": 2874.34, "dur": 1.39, "end": 2875.73, "text": "PATRICK H. WINSTON: Cello."}, {"index": 895, "start": 2875.73, "dur": 3.631, "end": 2879.361, "text": "You didn&#39;t see the little\ngirl or the instructor."}, {"index": 896, "start": 2879.361, "dur": 0.791, "end": 2880.152, "text": "How about this one?"}, {"index": 897, "start": 2880.152, "dur": 1.178, "end": 2881.33, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 898, "start": 2881.33, "dur": 0.5, "end": 2881.83, "text": "PATRICK H. WINSTON: What?"}, {"index": 899, "start": 2881.83, "dur": 1, "end": 2882.83, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 900, "start": 2882.83, "dur": 0.958, "end": 2883.788, "text": "PATRICK H. WINSTON: No."}, {"index": 901, "start": 2883.788, "dur": 3.417, "end": 2887.205}, {"index": 902, "start": 2887.205, "dur": 1.425, "end": 2888.63, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 903, "start": 2888.63, "dur": 2.05, "end": 2890.68, "text": "PATRICK H. WINSTON:\nIt&#39;s a grasshopper."}, {"index": 904, "start": 2890.68, "dur": 0.71, "end": 2891.39, "text": "What&#39;s this?"}, {"index": 905, "start": 2891.39, "dur": 0.94, "end": 2892.33, "text": "AUDIENCE: A wolf."}, {"index": 906, "start": 2892.33, "dur": 1.541, "end": 2893.871, "text": "PATRICK H. WINSTON:\nWow, you&#39;re good."}, {"index": 907, "start": 2893.871, "dur": 1.999, "end": 2895.87}, {"index": 908, "start": 2895.87, "dur": 1.823, "end": 2897.693, "text": "It&#39;s actually not\na two-headed wolf."}, {"index": 909, "start": 2897.693, "dur": 2.307, "end": 2900, "text": "[LAUGHTER]"}, {"index": 910, "start": 2900, "dur": 3.438, "end": 2903.438, "text": "It&#39;s two wolves that\nare close together."}, {"index": 911, "start": 2903.438, "dur": 1.256, "end": 2904.694, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 912, "start": 2904.694, "dur": 1.708, "end": 2906.402, "text": "PATRICK H. WINSTON:\nThat&#39;s a bird, right?"}, {"index": 913, "start": 2906.402, "dur": 1.373, "end": 2907.775, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 914, "start": 2907.775, "dur": 1.375, "end": 2909.15, "text": "PATRICK H. WINSTON:\nGood for you."}, {"index": 915, "start": 2909.15, "dur": 0.687, "end": 2909.837, "text": "It&#39;s a rabbit."}, {"index": 916, "start": 2909.837, "dur": 2.357, "end": 2912.194, "text": "[LAUGHTER]"}, {"index": 917, "start": 2912.194, "dur": 0.625, "end": 2912.819, "text": "How about that?"}, {"index": 918, "start": 2912.819, "dur": 1, "end": 2913.819, "text": "[? AUDIENCE: Giraffe. ?]"}, {"index": 919, "start": 2913.819, "dur": 2.221, "end": 2916.04}, {"index": 920, "start": 2916.04, "dur": 2.322, "end": 2918.362, "text": "PATRICK H. WINSTON:\nRussian wolfhound."}, {"index": 921, "start": 2918.362, "dur": 0.916, "end": 2919.278, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 922, "start": 2919.278, "dur": 7.137, "end": 2926.415}, {"index": 923, "start": 2926.415, "dur": 1.875, "end": 2928.29, "text": "PATRICK H. WINSTON: If\nyou&#39;ve been to Venice,"}, {"index": 924, "start": 2928.29, "dur": 1.024, "end": 2929.314, "text": "you recognize this."}, {"index": 925, "start": 2929.314, "dur": 2.606, "end": 2931.92, "text": "AUDIENCE: [INAUDIBLE]."}, {"index": 926, "start": 2931.92, "dur": 2.31, "end": 2934.23, "text": "PATRICK H. WINSTON:\nSo bottom line"}, {"index": 927, "start": 2934.23, "dur": 1.73, "end": 2935.96, "text": "is that these things\nare an engineering"}, {"index": 928, "start": 2935.96, "dur": 4.576, "end": 2940.536, "text": "marvel and do great things,\nbut they don&#39;t see like we see."}, {"index": 929, "start": 2940.536, "dur": 4.728, "end": 2945.264}]